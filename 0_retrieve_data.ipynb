{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e514d-2494-44da-9767-b9a02393bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import subprocess\n",
    "from src.data_funcs import get_stids\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3a268-3a2e-4190-88be-2492c50d18e3",
   "metadata": {},
   "source": [
    "## Retrieve Data From OpenWFM\n",
    "\n",
    "The data is a formatted RAWS dictionary using code from `wrfxpy`. To reproduce data creation, see: _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46d754-6f92-4bed-983c-e1194382e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"raws_rocky_202305-202405.pkl\"\n",
    "\n",
    "# Check for file locally, retrieve with wget if not\n",
    "if not osp.exists(filename):\n",
    "    import subprocess\n",
    "    base_url = \"https://demo.openwfm.org/web/data/fmda/dicts/\"\n",
    "    print(f\"Retrieving data {osp.join(base_url, filename)}\")\n",
    "    subprocess.call(f\"wget -P data {osp.join(base_url, filename)}\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9b4d1-a4b1-4021-b35b-f14751a56029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "dat = pd.read_pickle(f\"data/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0a5de-bc71-4b77-b7ed-4a4b8f510eeb",
   "metadata": {},
   "source": [
    "## Format Data in DataFrame\n",
    "\n",
    "The data from openwfm is a nested dictionary. The top-level dictionary keys are organized by RAWS station ID. Data is collected from each RAWS station that has fuel moisture observations. A subset of those stations have more atmospheric data sensors. In this analysis, we will limit the RAWS stations to those with a complete set of sensor ID for variables of theoretical interest to fuel moisture modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe36d8-50d8-4382-8fb2-ca207d14c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_vars = [\"Ew\", \"Ed\", \"temp\", \"rh\", \"rain\", \"precip_accum\", \"fm\", \"wind\", \"solar\", \"time_raws\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630136ca-e2dd-4942-b978-b55559b25bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_moisture(arr, name=None, verbose=True):\n",
    "    # Function to filter data moisture data, apply to fm, Ed, and Ew\n",
    "    # Filters: \n",
    "        # values less than 1: not physically reasonable\n",
    "    arr[arr < 1] = np.nan\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def filter_rain(rain, verbose=True):\n",
    "    # Filter rain data observations\n",
    "    # Filters:\n",
    "        # Less than zero\n",
    "        # Greater than 50\n",
    "    rain[rain > 50] = np.NaN # filter out erroneously high\n",
    "    rain[rain < 0] = np.NaN # filter out negative, results from diff function after precipa goes to zero\n",
    "\n",
    "    return rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373def17-e0a3-4376-9a0f-5194b9c2fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(d):\n",
    "    # Input: dictionary d\n",
    "\n",
    "    d[\"fm\"] = filter_moisture(d[\"fm\"], name=\"fm\")\n",
    "    d[\"Ed\"] = filter_moisture(d[\"Ed\"], name=\"Ed\")\n",
    "    d[\"Ew\"] = filter_moisture(d[\"Ew\"], name=\"Ew\")\n",
    "    d[\"rain\"] = filter_rain(d[\"rain\"])\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13e5d-dc2b-4f06-a76f-905376df0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(d, tvars=raws_vars):\n",
    "    # RAWS timeseries vars\n",
    "    data1 = {key: d[\"RAWS\"][key] for key in tvars if key in d[\"RAWS\"]}\n",
    "    # Static RAWS station location vars, fill to length of previous\n",
    "    data2 = {key: np.full(len(d[\"RAWS\"][\"time_raws\"]), value) for key, value in d['loc'].items()}\n",
    "    # Combine into DF\n",
    "    df = pd.DataFrame({**data1, **data2})\n",
    "    # Add Derived Time Fields: day of year, hour of day\n",
    "    df[\"time_raws\"]=np.array([datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%SZ\") for dt_str in subdict[\"RAWS\"][\"time_raws\"]])\n",
    "    df.index=np.array([datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%SZ\") for dt_str in subdict[\"RAWS\"][\"time_raws\"]])\n",
    "    df[\"hour\"]=df.index.hour\n",
    "    df[\"doy\"]=df.index.dayofyear\n",
    "    df[\"date\"]=df.index\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5eb0d-b50b-4069-a927-008de18aaf58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = [] # empty list to collect data\n",
    "\n",
    "for k in dat.keys():\n",
    "    print(\"~\"*50)\n",
    "    subdict = dat[k]\n",
    "    loc = subdict[\"loc\"]\n",
    "    print(loc)\n",
    "    if all(key in subdict[\"RAWS\"] for key in raws_vars):\n",
    "        print(f\"Formatting data for {loc['STID']}\")\n",
    "        subdict[\"RAWS\"] = fix_data(subdict[\"RAWS\"])\n",
    "        dfs.append(dict_to_df(subdict))\n",
    "        # plt.figure()\n",
    "        # plt.plot(raws['fm'])\n",
    "        # plt.title(f\"RAWS Station {loc['STID']}\")\n",
    "    else:\n",
    "        print(f\"Incomplete sensor variables for {loc['STID']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb263389-31d1-40a0-99ba-7ce3b79970cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d3e4d-ca64-4b3a-adce-ff5e4886ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Dataframe\n",
    "with open(osp.join(\"data\", \"raws_df0.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670b3a2-2a3e-4983-a084-e7e3b51ec0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864cb95-5754-4720-8871-f1cf0af808ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
