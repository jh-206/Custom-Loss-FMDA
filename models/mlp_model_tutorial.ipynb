{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6fb94d-e324-436c-90da-64868202cdd7",
   "metadata": {},
   "source": [
    "# Model Tutorial: MultiLayer Perceptron (Simple Neural Network)\n",
    "\n",
    "The purpose of this notebook is to demonstrate how to train and predict a simple Neural Network used in this project. First, we will demonstrate the basic code, and then reproduce the results using a custom class `MLP` to make the code consistent for multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acea576-0a24-40b0-abee-fb0e189eee3d",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd9b43-5505-4e1d-9647-79c24311fc6a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba1df9-254c-4f34-a858-d9ab817c0202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "# Local modules\n",
    "# from fmda_models import XGB\n",
    "import reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf873ab7-36cb-49f9-9752-0d9a0a3c3fca",
   "metadata": {},
   "source": [
    "## Read and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89336e-82cc-4a7a-86b9-68355c50e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/rocky_2023_06-08.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0232537-ebf0-44c2-b175-22bc08078e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "reproducibility.set_seed(123)\n",
    "\n",
    "# Create Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"Ed\", \"Ew\"]], df['fm'], test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826d22d-be79-4220-91ab-ff93173fb3db",
   "metadata": {},
   "source": [
    "## Manually Code MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a75bbf-e6a1-47c5-9b24-cdb290247df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe36ec-121c-4331-8e38-75680d18f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_units': 10,\n",
    "    'activation': 'relu',\n",
    "    'optimizer': 'adam',\n",
    "    'epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'validation_split': 0.2,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 0.001  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47875768-5df1-454e-beb0-640b6c615397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(params['hidden_units'], activation=params['activation'], input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(params['dropout']),  # Dropout layer\n",
    "    tf.keras.layers.Dense(1)  # Output layer with a single neuron for regression\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411dd99-5bfe-4bc4-b265-a01211b0edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], validation_split=params['validation_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb7260-63b5-4e94-9234-972dbbf4dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = model.predict(X_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c33735-755e-464c-b9ba-d709ec3bee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE for the training data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, fitted))\n",
    "\n",
    "# Calculate R-squared for the training data\n",
    "r2_train = r2_score(y_train, fitted)\n",
    "\n",
    "# Calculate RMSE for the test data\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "# Calculate R-squared for the test data\n",
    "r2_test = r2_score(y_test, preds)\n",
    "\n",
    "print(\"RMSE for training data:\", rmse_train)\n",
    "print(\"R-squared for training data:\", r2_train)\n",
    "print(\"RMSE for test data:\", rmse_test)\n",
    "print(\"R-squared for test data:\", r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cf89f-9166-4690-a7e3-df78f766185c",
   "metadata": {},
   "source": [
    "## Reproduce using MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff06d1c-7797-42d2-8777-4ecadafce7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params.yaml', 'r') as file:\n",
    "    all_params = yaml.safe_load(file)\n",
    "\n",
    "params = all_params[\"mlp\"]\n",
    "params[\"input_dim\"] = X_train.shape[1] # Define Input shape based on X_train\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21422161-e1c8-4dec-9b66-276884d26fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "    Wrapper class for multilayer perceptron neural network model.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    params : dict\n",
    "        Parameters to be passed to the XGBoost model.\n",
    "    loss : \n",
    "    Attributes:\n",
    "    -----------\n",
    "    model : keras.engine.sequential.Sequential\n",
    "        Underlying neural network.\n",
    "    params : dict\n",
    "        Parameters passed to the NN model.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    fit(X_train, y_train):\n",
    "        Train the model on the training data.\n",
    "    predict(X_test):\n",
    "        Make predictions using the trained model.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, loss='mean_squared_error'):\n",
    "        \"\"\"\n",
    "        Initialize the MLP class.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        params : dict\n",
    "            HyperParameters to be passed to the XGBoost model.\n",
    "        objective : str or custom func.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.params['loss'] = loss\n",
    "        self.model = self._build_model()\n",
    "        self.compile_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.params['hidden_units'], activation=self.params['activation'], input_shape=(self.params['input_dim'],)),\n",
    "            tf.keras.layers.Dropout(self.params['dropout']),  # Dropout layer\n",
    "            tf.keras.layers.Dense(1)  # Output layer with a single neuron for regression\n",
    "        ])\n",
    "        return model\n",
    "    def compile_model(self):\n",
    "        tf.keras.optimizers.Adam(learning_rate=self.params['learning_rate'])\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self.params['loss'],\n",
    "                           metrics=self.params.get('metrics', ['accuracy']))\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the XGBoost model on the training data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_train : array-like or sparse matrix of shape (n_samples, n_features)\n",
    "            Training input samples.\n",
    "        y_train : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "        \"\"\"\n",
    "        self.model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], validation_split=params['validation_split'])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_test : array-like or sparse matrix of shape (n_samples, n_features)\n",
    "            Test input samples.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        array-like of shape (n_samples,)\n",
    "            Predicted target values.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X_test)\n",
    "    def summary(self):\n",
    "        return self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f9445-7b0a-430a-86a6-da96ff96a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "mlp = MLP(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c063a25-1806-4f4e-8e61-45d80b371617",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f8421-814f-4324-8f3c-78b27d454098",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = mlp.predict(X_train)\n",
    "preds = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fda14a-5e4f-49d1-b9d6-fc66a36e9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE for the training data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, fitted))\n",
    "\n",
    "# Calculate R-squared for the training data\n",
    "r2_train = r2_score(y_train, fitted)\n",
    "\n",
    "# Calculate RMSE for the test data\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "# Calculate R-squared for the test data\n",
    "r2_test = r2_score(y_test, preds)\n",
    "\n",
    "print(\"RMSE for training data:\", rmse_train)\n",
    "print(\"R-squared for training data:\", r2_train)\n",
    "print(\"RMSE for test data:\", rmse_test)\n",
    "print(\"R-squared for test data:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e8b74-dec0-4039-a2b4-4a7f5d090a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d09594-8612-4430-b39b-d71cce67234b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
