{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e42afd-c21f-4474-8172-b782837e949f",
   "metadata": {},
   "source": [
    "# Test Loss Functions on Smaller Sets\n",
    "\n",
    "The notebook `2_loss` was meant for getting a statistical estimate of the prediction RMSE for the various loss functions. This notebook is meant to examine specific cases on a more granular level. The goal is to identify particularly dry and particularly wet periods and see how the loss functions behave. It is hypothesized that the weighted loss functions will perform better in very dry conditions when FMC is in the critical range with respect to ROS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45132b8-5ab5-4254-8c72-a6b179a3be62",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49507edf-5e75-4df2-acca-5f283b74f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import pickle\n",
    "import os.path as osp\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "# Local modules\n",
    "from data_funcs import train_test_split_spacetime\n",
    "from fmda_models import LM, XGB, RF\n",
    "from metrics import ros_0wind, ros_3wind, rmse\n",
    "from utils import initialize_models, create_exp_function, loss_setup\n",
    "import reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68d0a0-39da-45a9-adff-f06ea059aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/raws_df.pkl\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b79cac-c0e8-4a66-b5ad-f5ddce9f1045",
   "metadata": {},
   "source": [
    "## Find Time Periods\n",
    "\n",
    "We search for the period with the highest average ROS. We expect this period to be where the weighted loss functions perform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e42a5-7712-44f7-ab76-5a8586e88b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over same time periods used in main analysis\n",
    "# Save average FMC and average ROS\n",
    "fms = []\n",
    "rs= []\n",
    "t = df.index.min()\n",
    "ts = []\n",
    "i = 0\n",
    "tdelta = 2 # number of days to shift train/test period\n",
    "while t <= (df.index.max() - timedelta(days = 30)):\n",
    "    print(\"~\"*50)\n",
    "    ts.append(t)\n",
    "    print(f\"Time Period: {i}\")\n",
    "    print(f\"Time Period Start: {t}\")\n",
    "    print(f\"Time Period End: {t + timedelta(days=30)}\")\n",
    "    # Build train/test from 30 day period after t\n",
    "    df_temp = df[\n",
    "        (df.index >= t) & (df.index < (t + timedelta(days=30)))\n",
    "    ]\n",
    "\n",
    "    # Extract info\n",
    "    print(f\"Mean FMC: {df_temp.fm.mean()}\")\n",
    "    fms.append(df_temp.fm.mean())\n",
    "    print(f\"Mean ROS: {ros_3wind(df_temp.fm).mean()}\")\n",
    "    rs.append(ros_3wind(df_temp.fm).mean())\n",
    "\n",
    "\n",
    "    # # Iterate test period by 2 so no overlap\n",
    "    i+= 1 # iteration counter\n",
    "    t = t + timedelta(days=tdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcd997-45bb-4e94-80e4-bbdc4b1f0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# First histogram\n",
    "ax1.hist(fms, bins=20, color='skyblue', edgecolor='black')\n",
    "ax1.set_title('A: Mean FMC by 30-day Time Period')\n",
    "ax1.set_ylabel(\"FMC (%)\")\n",
    "\n",
    "# Second histogram\n",
    "ax2.hist(rs, bins=20, color='salmon', edgecolor='black')\n",
    "ax2.set_title('B: Mean ROS by 30-day Time Period')\n",
    "ax2.set_ylabel(\"ROS (m/s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad31e15-6ed4-4116-802e-9378d882f421",
   "metadata": {},
   "source": [
    "The time periods with the highest average ROS correspond to the lowest average FMC, and vice-versa. The wettest period (highest FMC and lowest ROS), was in January to February. The driest period (lowest FMC and highest ROS) was in October to February. In 2023 rainfall was very los in October and Nobember: https://www.weather.gov/media/bou/2023DenverClimateSummary.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5be89d-b4f0-464c-9732-a98ba4e67fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Time Periods: {len(fms)}\")\n",
    "print(\"~\"*50)\n",
    "print(f\"Max FMC Period: {np.argmax(np.array(fms))}\")\n",
    "print(f\"Min ROS Period: {np.argmin(np.array(rs))}\")\n",
    "print(f\"Time Range: {(str(ts[np.argmax(np.array(fms))]), str(ts[np.argmax(np.array(fms))]+timedelta(days=30)))}\")\n",
    "print(\"~\"*50)\n",
    "print(f\"Min FMC Period: {np.argmin(np.array(fms))}\")\n",
    "print(f\"Max ROS Period: {np.argmax(np.array(rs))}\")\n",
    "print(f\"Time Range: {(str(ts[np.argmin(np.array(fms))]), str(ts[np.argmin(np.array(fms))]+timedelta(days=30)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6b6c4-a7ad-48c7-ac40-4faea92e844a",
   "metadata": {},
   "source": [
    "## Modeling Setup\n",
    "\n",
    "Loss functions will be standard MSE, the ROS based on 3m/s wind, and the weighted loss function with $\\omega = 0.0367$, which performed the best in the main analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b48de8-335a-40e9-8def-47bc21a6dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/params.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0536837-4a25-4d95-9e82-a25051e4a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, loss_dict = loss_setup(params, ws=np.array([0.0367]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bf424-933b-4bc1-b9b1-09ac79943098",
   "metadata": {},
   "source": [
    "### Model Driest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52238b1-63d0-409a-a992-51d3b06d75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=ts[np.argmin(np.array(fms))]\n",
    "cols = [\"Ed\", \"rain\", \"wind\", \"solar\", \"hour\", \"doy\", \"lat\", \"lon\", 'elev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf811087-a8a7-4296-9ca7-92b962b035de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reproducibility.set_seed(42)\n",
    "nreps = 3\n",
    "for i in range(0, nreps):\n",
    "    df_temp = df[\n",
    "        (df.index >= t) & (df.index < (t + timedelta(days=30)))\n",
    "    ]\n",
    "    X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "        df_temp, \n",
    "        test_days = 2,\n",
    "        spatial_test_frac = 0.2,\n",
    "        verbose = True\n",
    "    )\n",
    "    X_train = X_train[cols]\n",
    "    X_test = X_test[cols]\n",
    "    # Run models\n",
    "    for l in loss_dict:\n",
    "        print(\"~\"*50)\n",
    "        print(f\"Running models for loss func: {l}\")\n",
    "        if loss_dict[l]['w_func'] is not None:\n",
    "            weights = loss_dict[l]['w_func'](y_train)\n",
    "        else:\n",
    "            weights = None\n",
    "        # Reinitialize models dictionary to prevent multiple fitting iterations\n",
    "        # if True:\n",
    "        #     models = initialize_models()\n",
    "        for mod in models:\n",
    "            print(f\"Fitting {mod}\")\n",
    "            models[mod].fit(X_train, y_train, weights)\n",
    "            preds = models[mod].predict(X_test)\n",
    "            loss_dict[l][f\"errs\"][mod][\"t\"].append(t)\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test\"].append(rmse(preds, y_test))\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test_ROS\"].append(rmse(ros_3wind(preds), ros_3wind(y_test)))\n",
    "            print(f\"Test RMSE for {mod}: {rmse(preds, y_test)}\")\n",
    "            print(f\"Test ROS RMSE for {mod}: {rmse(ros_3wind(preds), ros_3wind(y_test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119af68b-73f7-4137-9f21-65dc7ff962bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fm = []\n",
    "results_ros = []\n",
    "for l in loss_dict:\n",
    "    for mod in loss_dict[l][\"errs\"]:\n",
    "        errs = loss_dict[l][\"errs\"][mod]['rmse_test']\n",
    "        temp = {\n",
    "            'RMSE': loss_dict[l][\"errs\"][mod]['rmse_test'],\n",
    "            'Loss': [l] * len(errs),\n",
    "            'Model': [mod] * len(errs),\n",
    "            't': loss_dict[l][\"errs\"][mod]['t']\n",
    "        }\n",
    "        results_fm.append(pd.DataFrame(temp))\n",
    "        errs = loss_dict[l][\"errs\"][mod]['rmse_test_ROS']\n",
    "        temp = {\n",
    "            'RMSE': loss_dict[l][\"errs\"][mod]['rmse_test_ROS'],\n",
    "            'Loss': [l] * len(errs),\n",
    "            'Model': [mod] * len(errs),\n",
    "            't': loss_dict[l][\"errs\"][mod]['t']\n",
    "        }\n",
    "        results_ros.append(pd.DataFrame(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7052f8c-1445-4946-aabb-67be7780242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fm = pd.concat(results_fm)\n",
    "results_ros = pd.concat(results_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5068c-a3e7-4de8-a715-6b74207fdadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fm.groupby(['Loss'], sort=False).agg(    Mean=('RMSE', 'mean'),\n",
    "    Min=('RMSE', 'min'),\n",
    "    Max=('RMSE', 'max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cd02f-76f8-4db3-87f6-888ba7175168",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ros.groupby(['Loss'], sort=False).agg(    \n",
    "    Mean=('RMSE', 'mean'),\n",
    "    Min=('RMSE', 'min'),\n",
    "    Max=('RMSE', 'max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330fd14-b3c5-4306-bba5-45772f2aa46a",
   "metadata": {},
   "source": [
    "### Model Wettest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35680fc-bd3e-4d3a-869e-d5dbc2942690",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, loss_dict = loss_setup(params, ws=np.array([0.0367]))\n",
    "t=ts[np.argmax(np.array(fms))]\n",
    "cols = [\"Ed\", \"rain\", \"wind\", \"solar\", \"hour\", \"doy\", \"lat\", \"lon\", 'elev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ee310-7521-49a1-a423-41135da70555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reproducibility.set_seed(42)\n",
    "nreps = 3\n",
    "for i in range(0, nreps):\n",
    "    df_temp = df[\n",
    "        (df.index >= t) & (df.index < (t + timedelta(days=30)))\n",
    "    ]\n",
    "    X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "        df_temp, \n",
    "        test_days = 2,\n",
    "        spatial_test_frac = 0.2,\n",
    "        verbose = True\n",
    "    )\n",
    "    X_train = X_train[cols]\n",
    "    X_test = X_test[cols]\n",
    "    # Run models\n",
    "    for l in loss_dict:\n",
    "        print(\"~\"*50)\n",
    "        print(f\"Running models for loss func: {l}\")\n",
    "        if loss_dict[l]['w_func'] is not None:\n",
    "            weights = loss_dict[l]['w_func'](y_train)\n",
    "        else:\n",
    "            weights = None\n",
    "        # Reinitialize models dictionary to prevent multiple fitting iterations\n",
    "        # if True:\n",
    "        #     models = initialize_models()\n",
    "        for mod in models:\n",
    "            print(f\"Fitting {mod}\")\n",
    "            models[mod].fit(X_train, y_train, weights)\n",
    "            preds = models[mod].predict(X_test)\n",
    "            loss_dict[l][f\"errs\"][mod][\"t\"].append(t)\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test\"].append(rmse(preds, y_test))\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test_ROS\"].append(rmse(ros_3wind(preds), ros_3wind(y_test)))\n",
    "            print(f\"Test RMSE for {mod}: {rmse(preds, y_test)}\")\n",
    "            print(f\"Test ROS RMSE for {mod}: {rmse(ros_3wind(preds), ros_3wind(y_test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9f182-febf-41b5-817f-6f2cae3b62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fm = []\n",
    "results_ros = []\n",
    "for l in loss_dict:\n",
    "    for mod in loss_dict[l][\"errs\"]:\n",
    "        errs = loss_dict[l][\"errs\"][mod]['rmse_test']\n",
    "        temp = {\n",
    "            'RMSE': loss_dict[l][\"errs\"][mod]['rmse_test'],\n",
    "            'Loss': [l] * len(errs),\n",
    "            'Model': [mod] * len(errs),\n",
    "            't': loss_dict[l][\"errs\"][mod]['t']\n",
    "        }\n",
    "        results_fm.append(pd.DataFrame(temp))\n",
    "        errs = loss_dict[l][\"errs\"][mod]['rmse_test_ROS']\n",
    "        temp = {\n",
    "            'RMSE': loss_dict[l][\"errs\"][mod]['rmse_test_ROS'],\n",
    "            'Loss': [l] * len(errs),\n",
    "            'Model': [mod] * len(errs),\n",
    "            't': loss_dict[l][\"errs\"][mod]['t']\n",
    "        }\n",
    "        results_ros.append(pd.DataFrame(temp))\n",
    "\n",
    "results_fm = pd.concat(results_fm)\n",
    "results_ros = pd.concat(results_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d27ff-f619-4abf-b385-621a4b4f23a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fm.groupby(['Loss'], sort=False).agg(    \n",
    "    Mean=('RMSE', 'mean'),\n",
    "    Min=('RMSE', 'min'),\n",
    "    Max=('RMSE', 'max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891d5ec-d09e-436a-a6ce-c1ef901456be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ros.groupby(['Loss'], sort=False).agg(    \n",
    "    Mean=('RMSE', 'mean'),\n",
    "    Min=('RMSE', 'min'),\n",
    "    Max=('RMSE', 'max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6596da-474a-4bae-957d-43b4410281b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percent Reduction in RMSE for ROS from Best Exp. Loss: {100*(results_ros[results_ros.Loss == 'MSE'].RMSE.mean()- results_ros[results_ros.Loss == 'exp_0.0367'].RMSE.mean())/results_ros[results_ros.Loss == 'MSE'].RMSE.mean()}\")\n",
    "print(f\"Percent Reduction in RMSE for ROS from ROS Loss: {100*(results_ros[results_ros.Loss == 'MSE'].RMSE.mean()- results_ros[results_ros.Loss == 'ROS'].RMSE.mean())/results_ros[results_ros.Loss == 'MSE'].RMSE.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d9785-4ac0-4c55-9028-345740c0b92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74ef52-1a69-4ac2-b3c5-a56c2956d563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
