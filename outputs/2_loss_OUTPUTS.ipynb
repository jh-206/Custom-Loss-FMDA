{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f01fe9-1006-4182-b26f-cd33eaeef062",
   "metadata": {},
   "source": [
    "# Test Loss Functions on Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375d5c58-a711-4371-91b3-6de72c7b9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "# Local modules\n",
    "from data_funcs import train_test_split_spacetime\n",
    "from fmda_models import LM, XGB, RF\n",
    "from metrics import ros, rmse\n",
    "import reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb86ca1-547c-4eb8-a241-a3ad3f96fec3",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6042d139-16f4-45a7-bdbf-25e7926b0bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ew', 'Ed', 'temp', 'rh', 'rain', 'precip_accum', 'fm', 'wind', 'solar',\n",
       "       'time_raws', 'STID', 'lat', 'lon', 'elev', 'hour', 'doy', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data/raws_df.pkl\")\n",
    "df = df.dropna()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeef1588-8223-4462-ad1e-bfa7991a2b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ew</th>\n",
       "      <th>Ed</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>rain</th>\n",
       "      <th>precip_accum</th>\n",
       "      <th>fm</th>\n",
       "      <th>wind</th>\n",
       "      <th>solar</th>\n",
       "      <th>time_raws</th>\n",
       "      <th>STID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>hour</th>\n",
       "      <th>doy</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-17 03:09:00</th>\n",
       "      <td>13.147834</td>\n",
       "      <td>14.552503</td>\n",
       "      <td>284.817</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>470.408</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-05-17 03:09:00</td>\n",
       "      <td>CPTC2</td>\n",
       "      <td>38.45944</td>\n",
       "      <td>-109.04694</td>\n",
       "      <td>8088</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>2023-05-17 03:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-17 04:09:00</th>\n",
       "      <td>13.247513</td>\n",
       "      <td>14.652182</td>\n",
       "      <td>284.261</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>470.408</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-17 04:09:00</td>\n",
       "      <td>CPTC2</td>\n",
       "      <td>38.45944</td>\n",
       "      <td>-109.04694</td>\n",
       "      <td>8088</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>2023-05-17 04:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-17 05:09:00</th>\n",
       "      <td>12.876054</td>\n",
       "      <td>14.274707</td>\n",
       "      <td>284.261</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>470.408</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-17 05:09:00</td>\n",
       "      <td>CPTC2</td>\n",
       "      <td>38.45944</td>\n",
       "      <td>-109.04694</td>\n",
       "      <td>8088</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2023-05-17 05:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-17 06:09:00</th>\n",
       "      <td>13.446692</td>\n",
       "      <td>14.851361</td>\n",
       "      <td>283.150</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>470.408</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-17 06:09:00</td>\n",
       "      <td>CPTC2</td>\n",
       "      <td>38.45944</td>\n",
       "      <td>-109.04694</td>\n",
       "      <td>8088</td>\n",
       "      <td>6</td>\n",
       "      <td>137</td>\n",
       "      <td>2023-05-17 06:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-17 07:09:00</th>\n",
       "      <td>14.000874</td>\n",
       "      <td>15.412836</td>\n",
       "      <td>283.150</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>470.408</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-17 07:09:00</td>\n",
       "      <td>CPTC2</td>\n",
       "      <td>38.45944</td>\n",
       "      <td>-109.04694</td>\n",
       "      <td>8088</td>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>2023-05-17 07:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 19:17:00</th>\n",
       "      <td>5.988904</td>\n",
       "      <td>7.156126</td>\n",
       "      <td>293.706</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.096</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.343</td>\n",
       "      <td>970.0</td>\n",
       "      <td>2024-05-14 19:17:00</td>\n",
       "      <td>TT815</td>\n",
       "      <td>37.52272</td>\n",
       "      <td>-108.48178</td>\n",
       "      <td>7576</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>2024-05-14 19:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 20:17:00</th>\n",
       "      <td>9.688784</td>\n",
       "      <td>11.031949</td>\n",
       "      <td>290.372</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.096</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.448</td>\n",
       "      <td>426.0</td>\n",
       "      <td>2024-05-14 20:17:00</td>\n",
       "      <td>TT815</td>\n",
       "      <td>37.52272</td>\n",
       "      <td>-108.48178</td>\n",
       "      <td>7576</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>2024-05-14 20:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 21:17:00</th>\n",
       "      <td>11.794500</td>\n",
       "      <td>13.189754</td>\n",
       "      <td>289.261</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>11.176</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>594.0</td>\n",
       "      <td>2024-05-14 21:17:00</td>\n",
       "      <td>TT815</td>\n",
       "      <td>37.52272</td>\n",
       "      <td>-108.48178</td>\n",
       "      <td>7576</td>\n",
       "      <td>21</td>\n",
       "      <td>135</td>\n",
       "      <td>2024-05-14 21:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 22:17:00</th>\n",
       "      <td>7.987530</td>\n",
       "      <td>9.267817</td>\n",
       "      <td>292.039</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.176</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.790</td>\n",
       "      <td>742.0</td>\n",
       "      <td>2024-05-14 22:17:00</td>\n",
       "      <td>TT815</td>\n",
       "      <td>37.52272</td>\n",
       "      <td>-108.48178</td>\n",
       "      <td>7576</td>\n",
       "      <td>22</td>\n",
       "      <td>135</td>\n",
       "      <td>2024-05-14 22:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 23:17:00</th>\n",
       "      <td>7.970651</td>\n",
       "      <td>9.239580</td>\n",
       "      <td>290.928</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.176</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.895</td>\n",
       "      <td>362.0</td>\n",
       "      <td>2024-05-14 23:17:00</td>\n",
       "      <td>TT815</td>\n",
       "      <td>37.52272</td>\n",
       "      <td>-108.48178</td>\n",
       "      <td>7576</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>2024-05-14 23:17:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883680 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Ew         Ed     temp    rh  rain  precip_accum  \\\n",
       "2023-05-17 03:09:00  13.147834  14.552503  284.817  48.0  0.00       470.408   \n",
       "2023-05-17 04:09:00  13.247513  14.652182  284.261  48.0  0.00       470.408   \n",
       "2023-05-17 05:09:00  12.876054  14.274707  284.261  46.0  0.00       470.408   \n",
       "2023-05-17 06:09:00  13.446692  14.851361  283.150  48.0  0.00       470.408   \n",
       "2023-05-17 07:09:00  14.000874  15.412836  283.150  51.0  0.00       470.408   \n",
       "...                        ...        ...      ...   ...   ...           ...   \n",
       "2024-05-14 19:17:00   5.988904   7.156126  293.706  20.0  0.00         6.096   \n",
       "2024-05-14 20:17:00   9.688784  11.031949  290.372  35.0  0.00         6.096   \n",
       "2024-05-14 21:17:00  11.794500  13.189754  289.261  45.0  5.08        11.176   \n",
       "2024-05-14 22:17:00   7.987530   9.267817  292.039  28.0  0.00        11.176   \n",
       "2024-05-14 23:17:00   7.970651   9.239580  290.928  27.0  0.00        11.176   \n",
       "\n",
       "                      fm   wind  solar           time_raws   STID       lat  \\\n",
       "2023-05-17 03:09:00  7.5  1.790    1.0 2023-05-17 03:09:00  CPTC2  38.45944   \n",
       "2023-05-17 04:09:00  8.1  1.790    0.0 2023-05-17 04:09:00  CPTC2  38.45944   \n",
       "2023-05-17 05:09:00  8.6  1.790    0.0 2023-05-17 05:09:00  CPTC2  38.45944   \n",
       "2023-05-17 06:09:00  9.2  1.790    0.0 2023-05-17 06:09:00  CPTC2  38.45944   \n",
       "2023-05-17 07:09:00  9.6  1.790    0.0 2023-05-17 07:09:00  CPTC2  38.45944   \n",
       "...                  ...    ...    ...                 ...    ...       ...   \n",
       "2024-05-14 19:17:00  9.4  1.343  970.0 2024-05-14 19:17:00  TT815  37.52272   \n",
       "2024-05-14 20:17:00  7.3  0.448  426.0 2024-05-14 20:17:00  TT815  37.52272   \n",
       "2024-05-14 21:17:00  8.0  1.343  594.0 2024-05-14 21:17:00  TT815  37.52272   \n",
       "2024-05-14 22:17:00  8.0  1.790  742.0 2024-05-14 22:17:00  TT815  37.52272   \n",
       "2024-05-14 23:17:00  8.2  0.895  362.0 2024-05-14 23:17:00  TT815  37.52272   \n",
       "\n",
       "                           lon  elev  hour  doy                date  \n",
       "2023-05-17 03:09:00 -109.04694  8088     3  137 2023-05-17 03:09:00  \n",
       "2023-05-17 04:09:00 -109.04694  8088     4  137 2023-05-17 04:09:00  \n",
       "2023-05-17 05:09:00 -109.04694  8088     5  137 2023-05-17 05:09:00  \n",
       "2023-05-17 06:09:00 -109.04694  8088     6  137 2023-05-17 06:09:00  \n",
       "2023-05-17 07:09:00 -109.04694  8088     7  137 2023-05-17 07:09:00  \n",
       "...                        ...   ...   ...  ...                 ...  \n",
       "2024-05-14 19:17:00 -108.48178  7576    19  135 2024-05-14 19:17:00  \n",
       "2024-05-14 20:17:00 -108.48178  7576    20  135 2024-05-14 20:17:00  \n",
       "2024-05-14 21:17:00 -108.48178  7576    21  135 2024-05-14 21:17:00  \n",
       "2024-05-14 22:17:00 -108.48178  7576    22  135 2024-05-14 22:17:00  \n",
       "2024-05-14 23:17:00 -108.48178  7576    23  135 2024-05-14 23:17:00  \n",
       "\n",
       "[883680 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d924a1-f9c9-45a0-bdb1-6fb145da83f6",
   "metadata": {},
   "source": [
    "## Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c207536-5c28-4c47-9c3d-592d7d323f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgb': {'max_depth': 3,\n",
       "  'eta': 0.1,\n",
       "  'min_child_weight': 1,\n",
       "  'subsample': 0.8,\n",
       "  'colsample_bytree': 0.9,\n",
       "  'scale_pos_weight': 1,\n",
       "  'n_estimators': 100,\n",
       "  'gamma': 0.1},\n",
       " 'rf': {'n_estimators': 25,\n",
       "  'criterion': 'squared_error',\n",
       "  'max_depth': 5,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'max_features': 0.8,\n",
       "  'bootstrap': True,\n",
       "  'max_samples': None,\n",
       "  'random_state': None,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False},\n",
       " 'mlp': {'hidden_units': 10,\n",
       "  'activation': 'relu',\n",
       "  'optimizer': 'adam',\n",
       "  'epochs': 10,\n",
       "  'batch_size': 32,\n",
       "  'validation_split': 0.2,\n",
       "  'dropout': 0.2,\n",
       "  'learning_rate': 0.001},\n",
       " 'lm': {'fit_intercept': True}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('models/params.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26a0074-804a-4953-9925-e235ca34ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    models = {\n",
    "        'xgb' : XGB(params['xgb']),\n",
    "        'lm' : LM(params['lm']),\n",
    "        'rf' : RF(params['rf'])\n",
    "    }\n",
    "\n",
    "    return models\n",
    "\n",
    "models = initialize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6fecb1-b761-45ff-88cf-e34ef36bcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp_function(w):\n",
    "    def exp_function(y_train):\n",
    "        return tf.exp(tf.multiply(-w, y_train))\n",
    "    return exp_function\n",
    "\n",
    "## Function test:\n",
    "# fun = create_exp_function(.05)\n",
    "# fun(y_train = np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1560f2-ca18-45b0-bc59-2ba433f224e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_setup(ws = None):\n",
    "    loss_fucs = [\"rss\", \"exp\", \"ros\"]\n",
    "    # set up return dictionary\n",
    "    loss = {\n",
    "        'rss' : {\n",
    "            'w_func' : None\n",
    "        }\n",
    "    } \n",
    "    # Using input omega parameter list, add dictionary key for exponential weighting for each omega in list \n",
    "    if ws is not None:\n",
    "        for w in ws:\n",
    "            assert isinstance(w, float) # Check that given list of floats\n",
    "            dname = f\"exp_{w}\" # create name of dictionary key\n",
    "            loss[dname] = {\n",
    "                'w_func' : create_exp_function(w)\n",
    "            }\n",
    "    loss[\"ros\"] = {'w_func': ros}\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542b0e03-bffd-4c5b-8971-ee974b720e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid of Omega Weights: [0.01   0.0367 0.0633 0.09   0.1167 0.1433 0.17   0.1967 0.2233 0.25  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rss': {'w_func': None},\n",
       " 'exp_0.01': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.0367': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.0633': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.09': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.1167': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.1433': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.17': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.1967': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.2233': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'exp_0.25': {'w_func': <function __main__.create_exp_function.<locals>.exp_function(y_train)>},\n",
       " 'ros': {'w_func': <function metrics.ros(fm)>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_grid=np.round(np.linspace(0.01, .25, 10), 4)\n",
    "print(f\"Grid of Omega Weights: {weight_grid}\")\n",
    "loss_dict = loss_setup(ws=weight_grid)\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaab300-75b6-4c7b-83d8-6964082edaf5",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d053e392-7e9a-4d45-9e66-7cae5649fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10',\n",
      "             '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04',\n",
      "             '2024-05'],\n",
      "            dtype='period[M]')\n",
      "resetting random seeds to 42\n",
      "Splitting data for month: 2023-06\n",
      "Total observations: (73724, 17)\n",
      "Number of Training Observations: 54410\n",
      "Number of Training Locations: 85\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-06-01 00:03:00', '2023-06-28 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1054\n",
      "Number of Test Locations: 22\n",
      "Time range Test: ('2023-06-29 00:06:00', '2023-06-30 23:58:00')\n"
     ]
    }
   ],
   "source": [
    "## COLUMNS SUBSET\n",
    "cols = [\"Ed\", \"rain\", \"wind\", \"solar\", \"hour\", \"doy\", \"lat\", \"lon\"]\n",
    "\n",
    "# Get unique month and year combos in the data\n",
    "month_year = df.index.to_period('M').unique()\n",
    "print(month_year)\n",
    "\n",
    "reproducibility.set_seed(42)\n",
    "\n",
    "# for my in month_year:\n",
    "#     print(\"~\"*50)\n",
    "#     month = my.month\n",
    "#     year = my.year\n",
    "#     print(f\"Splitting data for month: {my}\")\n",
    "#     df_temp = df[(df.index.month == month) & (df.index.year == year)]\n",
    "#     print(f\"Total observations: {df_temp.shape}\")\n",
    "#     X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "#         df_temp, \n",
    "#         test_days = 2,\n",
    "#         spatial_test_frac = 0.2,\n",
    "#         verbose = True\n",
    "#     )\n",
    "#     X_train = X_train[cols]\n",
    "#     X_test = X_test[cols]\n",
    "\n",
    "my = month_year[1]\n",
    "month = my.month\n",
    "year = my.year\n",
    "print(f\"Splitting data for month: {my}\")\n",
    "df_temp = df[(df.index.month == month) & (df.index.year == year)]\n",
    "print(f\"Total observations: {df_temp.shape}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "    df_temp, \n",
    "    test_days = 2,\n",
    "    spatial_test_frac = 0.2,\n",
    "    verbose = True\n",
    ")\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8f2d1-0879-4a96-b192-d19f696fa249",
   "metadata": {},
   "source": [
    "For each loss function and each model, we will collect 2 arrays of errors on the test set. One for the RMSE on the test fuel moisture observations, and another one on the RMSE for the same observations transformed to ROS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ee410d-34b9-46b7-acb6-171bca0d0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loss_dict:\n",
    "    loss_dict[l][f\"errs\"]={}\n",
    "    for mod in models:\n",
    "        loss_dict[l][f\"errs\"][mod] = {\n",
    "            \"rmse_test\" : [],\n",
    "            \"rmse_test_ROS\" : []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d5791c-79ae-4f1d-8b40-7e6fae9ea2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10',\n",
      "             '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04',\n",
      "             '2024-05'],\n",
      "            dtype='period[M]')\n",
      "resetting random seeds to 42\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-05\n",
      "Total observations: (35613, 17)\n",
      "Number of Training Observations: 24622\n",
      "Number of Training Locations: 83\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-05-17 02:22:00', '2023-05-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 932\n",
      "Number of Test Locations: 21\n",
      "Time range Test: ('2023-05-30 00:06:00', '2023-05-31 23:46:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.7385925044409207\n",
      "Test ROS RMSE for xgb: 0.0003745066086676341\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.2128661600451474\n",
      "Test ROS RMSE for lm: 0.0004685585283571196\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.9302667544359497\n",
      "Test ROS RMSE for rf: 0.0004408873721367646\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.7061526212774814\n",
      "Test ROS RMSE for xgb: 0.0003690967531621134\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.1748979787702765\n",
      "Test ROS RMSE for lm: 0.00046201211128641697\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.9251515812481665\n",
      "Test ROS RMSE for rf: 0.00043517570316173874\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.582720810505026\n",
      "Test ROS RMSE for xgb: 0.0003603656686894057\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0927781150246894\n",
      "Test ROS RMSE for lm: 0.00044782063527491083\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8567233780073185\n",
      "Test ROS RMSE for rf: 0.00043016221448547186\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.505428818540226\n",
      "Test ROS RMSE for xgb: 0.0003522648273406563\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0355135795936476\n",
      "Test ROS RMSE for lm: 0.0004371595629315713\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8061118629306057\n",
      "Test ROS RMSE for rf: 0.0004173484389366717\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.4498041461875606\n",
      "Test ROS RMSE for xgb: 0.0003513645964200894\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.003016247979858\n",
      "Test ROS RMSE for lm: 0.0004290637213899951\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8102422023916054\n",
      "Test ROS RMSE for rf: 0.0004150099510187856\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.418939565434958\n",
      "Test ROS RMSE for xgb: 0.0003417902761234249\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.997582308204479\n",
      "Test ROS RMSE for lm: 0.00042330473224883963\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.815597625558867\n",
      "Test ROS RMSE for rf: 0.0004149977559331907\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.5125397920135377\n",
      "Test ROS RMSE for xgb: 0.0003498432336430971\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0195356658991686\n",
      "Test ROS RMSE for lm: 0.0004199000528121512\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8256239826969862\n",
      "Test ROS RMSE for rf: 0.0004095792292752724\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.5624200646721027\n",
      "Test ROS RMSE for xgb: 0.0003558126089490578\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0665250455762503\n",
      "Test ROS RMSE for lm: 0.0004188497652904875\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.83555117059487\n",
      "Test ROS RMSE for rf: 0.000402362444349171\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.5821644649242472\n",
      "Test ROS RMSE for xgb: 0.0003607135826157378\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.133462208097362\n",
      "Test ROS RMSE for lm: 0.00042007358765853135\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8521209263227454\n",
      "Test ROS RMSE for rf: 0.0004009068766821294\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.6626364493256065\n",
      "Test ROS RMSE for xgb: 0.00036364792092334126\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.2138719841325822\n",
      "Test ROS RMSE for lm: 0.0004232800284370673\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.9309213308499005\n",
      "Test ROS RMSE for rf: 0.00040446439136375417\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.715743123567062\n",
      "Test ROS RMSE for xgb: 0.000368953869965668\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.30254150972763\n",
      "Test ROS RMSE for lm: 0.0004280835395045218\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.029352348015271\n",
      "Test ROS RMSE for rf: 0.00041070307261872245\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.60848868171559\n",
      "Test ROS RMSE for xgb: 0.0003700829650363277\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.054295147146086\n",
      "Test ROS RMSE for lm: 0.00044145159915937076\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.828239098280421\n",
      "Test ROS RMSE for rf: 0.0004191420209005902\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-06\n",
      "Total observations: (73724, 17)\n",
      "Number of Training Observations: 54565\n",
      "Number of Training Locations: 85\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-06-01 00:03:00', '2023-06-28 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1009\n",
      "Number of Test Locations: 21\n",
      "Time range Test: ('2023-06-28 23:59:00', '2023-06-30 23:59:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.402263732159503\n",
      "Test ROS RMSE for xgb: 0.0004839271801903373\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.181438264203181\n",
      "Test ROS RMSE for lm: 0.0006327655870814239\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.113908539782014\n",
      "Test ROS RMSE for rf: 0.0005985473126049475\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.399823614048139\n",
      "Test ROS RMSE for xgb: 0.00048401132801986627\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.153603268076135\n",
      "Test ROS RMSE for lm: 0.0006259818095881283\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.032641221547134\n",
      "Test ROS RMSE for rf: 0.0005925233350783519\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.3945171298881345\n",
      "Test ROS RMSE for xgb: 0.0004787097842111658\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.095492880200024\n",
      "Test ROS RMSE for lm: 0.0006101560965519143\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.892535615865644\n",
      "Test ROS RMSE for rf: 0.000575088020407492\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.406778302913497\n",
      "Test ROS RMSE for xgb: 0.00047091924582670235\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.064745691902398\n",
      "Test ROS RMSE for lm: 0.0005976244824737895\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.7363015531265025\n",
      "Test ROS RMSE for rf: 0.0005394907453248728\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.4571117263677555\n",
      "Test ROS RMSE for xgb: 0.00047066962915480074\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.069724351628094\n",
      "Test ROS RMSE for lm: 0.0005885544626035953\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.650751639548194\n",
      "Test ROS RMSE for rf: 0.0005215662638401582\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.5572010614562006\n",
      "Test ROS RMSE for xgb: 0.0004771773589236452\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.118574079849909\n",
      "Test ROS RMSE for lm: 0.0005832199828382576\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.6848462575920986\n",
      "Test ROS RMSE for rf: 0.0005098908034386496\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.6323615198572954\n",
      "Test ROS RMSE for xgb: 0.00048364687699695635\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.213129674420568\n",
      "Test ROS RMSE for lm: 0.0005816812212194116\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.747859994253808\n",
      "Test ROS RMSE for rf: 0.0005177734148562831\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.8049984073307734\n",
      "Test ROS RMSE for xgb: 0.0005013699581357596\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.348937636575218\n",
      "Test ROS RMSE for lm: 0.000583890033434389\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.8602982117753806\n",
      "Test ROS RMSE for rf: 0.0005180419083672385\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.9248885022587845\n",
      "Test ROS RMSE for xgb: 0.0005088090104335476\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.515070503157306\n",
      "Test ROS RMSE for lm: 0.000589641652608195\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.008006019488695\n",
      "Test ROS RMSE for rf: 0.0005209285467641555\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.100554742019284\n",
      "Test ROS RMSE for xgb: 0.0005246088391076233\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.698460367029656\n",
      "Test ROS RMSE for lm: 0.0005984246958926923\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.332936384121304\n",
      "Test ROS RMSE for rf: 0.0005453535152478619\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.3245298463076045\n",
      "Test ROS RMSE for xgb: 0.0005385932043927318\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.889658373778109\n",
      "Test ROS RMSE for lm: 0.0006097546034754875\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.68565176716635\n",
      "Test ROS RMSE for rf: 0.0005783558522629148\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.423084313444811\n",
      "Test ROS RMSE for xgb: 0.00047845316315149085\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.06152899374209\n",
      "Test ROS RMSE for lm: 0.000600383742454992\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.8166239336634944\n",
      "Test ROS RMSE for rf: 0.0005421545694276486\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-07\n",
      "Total observations: (77218, 17)\n",
      "Number of Training Observations: 57578\n",
      "Number of Training Locations: 87\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-07-01 00:01:00', '2023-07-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1053\n",
      "Number of Test Locations: 22\n",
      "Time range Test: ('2023-07-30 00:06:00', '2023-07-31 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.3964668518675993\n",
      "Test ROS RMSE for xgb: 0.0004609486554256114\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.297292372639861\n",
      "Test ROS RMSE for lm: 0.00047517733332536847\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.355072091884849\n",
      "Test ROS RMSE for rf: 0.000470562606929747\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.4183854951772004\n",
      "Test ROS RMSE for xgb: 0.0004654698862519907\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.3074536868929054\n",
      "Test ROS RMSE for lm: 0.0004729179735400565\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.368559508970647\n",
      "Test ROS RMSE for rf: 0.00046629274493363186\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.4844882524913756\n",
      "Test ROS RMSE for xgb: 0.00046681271279637454\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.3598437514504624\n",
      "Test ROS RMSE for lm: 0.0004698946054542261\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.514081380023902\n",
      "Test ROS RMSE for rf: 0.0004694648120523358\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.5509662257459516\n",
      "Test ROS RMSE for xgb: 0.00047092204364029513\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.4487159835434373\n",
      "Test ROS RMSE for lm: 0.00047105976297380525\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.6867578916027166\n",
      "Test ROS RMSE for rf: 0.00048450109261677\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.598229331568369\n",
      "Test ROS RMSE for xgb: 0.00047347931091350556\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.5727324658364306\n",
      "Test ROS RMSE for lm: 0.0004764003185366602\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.7073625853810697\n",
      "Test ROS RMSE for rf: 0.0004859958880842907\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.7546438651573135\n",
      "Test ROS RMSE for xgb: 0.0004933545888567967\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.724942555894761\n",
      "Test ROS RMSE for lm: 0.00048577296056928187\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.9331082260588013\n",
      "Test ROS RMSE for rf: 0.0005114380171347623\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.7998524714793196\n",
      "Test ROS RMSE for xgb: 0.0004927261878850029\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.8941647071816674\n",
      "Test ROS RMSE for lm: 0.0004986284311539462\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.9681567046507404\n",
      "Test ROS RMSE for rf: 0.0005138910944879485\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.012124219206864\n",
      "Test ROS RMSE for xgb: 0.0005191231599246931\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.070269630544717\n",
      "Test ROS RMSE for lm: 0.000514245949239723\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.0760117900067065\n",
      "Test ROS RMSE for rf: 0.0005184184305083553\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.149975813076077\n",
      "Test ROS RMSE for xgb: 0.000536429287645267\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.243063470613225\n",
      "Test ROS RMSE for lm: 0.0005316503225505208\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.3622932228046825\n",
      "Test ROS RMSE for rf: 0.0005676623800463017\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.184457183318366\n",
      "Test ROS RMSE for xgb: 0.000536159787148933\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.405566443697248\n",
      "Test ROS RMSE for lm: 0.0005499330116572652\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.512099561494086\n",
      "Test ROS RMSE for rf: 0.0005890305473876869\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.3622863494180955\n",
      "Test ROS RMSE for xgb: 0.0005615958429001581\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.555755512423652\n",
      "Test ROS RMSE for lm: 0.0005685754126167544\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.672826099169839\n",
      "Test ROS RMSE for rf: 0.00061017890067607\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.5051449805574997\n",
      "Test ROS RMSE for xgb: 0.000466919982622856\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.4130493840187563\n",
      "Test ROS RMSE for lm: 0.0004706834759579619\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.6491058003572427\n",
      "Test ROS RMSE for rf: 0.00048151902513217154\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-08\n",
      "Total observations: (79833, 17)\n",
      "Number of Training Observations: 60199\n",
      "Number of Training Locations: 88\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-08-01 00:01:00', '2023-08-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1052\n",
      "Number of Test Locations: 22\n",
      "Time range Test: ('2023-08-29 23:59:00', '2023-08-31 23:59:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.3656218076205477\n",
      "Test ROS RMSE for xgb: 0.0005082688999601277\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.366409788218593\n",
      "Test ROS RMSE for lm: 0.0006159970275554281\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.2312293296899552\n",
      "Test ROS RMSE for rf: 0.00048623069720083633\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.2956443103397404\n",
      "Test ROS RMSE for xgb: 0.0005015999995971652\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.339036593586592\n",
      "Test ROS RMSE for lm: 0.0006126342952752402\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.1826777922668565\n",
      "Test ROS RMSE for rf: 0.00047706244535204246\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.1486824470764803\n",
      "Test ROS RMSE for xgb: 0.00048554616500559524\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.2626966428636295\n",
      "Test ROS RMSE for lm: 0.0005965278772022627\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.119694493377375\n",
      "Test ROS RMSE for rf: 0.00047434646450268155\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.9900953889639506\n",
      "Test ROS RMSE for xgb: 0.00046556416252293897\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.1893946626859875\n",
      "Test ROS RMSE for lm: 0.0005748451881413267\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.0243619093212066\n",
      "Test ROS RMSE for rf: 0.0004638030972577664\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.8900432522862496\n",
      "Test ROS RMSE for xgb: 0.00045466090782549166\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.130839407485095\n",
      "Test ROS RMSE for lm: 0.0005528250148900485\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.993464595307214\n",
      "Test ROS RMSE for rf: 0.0004634689705346585\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.8112380829371886\n",
      "Test ROS RMSE for xgb: 0.0004461483154547768\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0976565161173015\n",
      "Test ROS RMSE for lm: 0.0005342663251544361\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.9452284439389076\n",
      "Test ROS RMSE for rf: 0.0004583267228674632\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.8056914400321182\n",
      "Test ROS RMSE for xgb: 0.0004480351570437447\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0940404351943966\n",
      "Test ROS RMSE for lm: 0.0005210046768591868\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.9484966628147906\n",
      "Test ROS RMSE for rf: 0.00046373720002135493\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.79004006341959\n",
      "Test ROS RMSE for xgb: 0.0004440717370228517\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.117472436002133\n",
      "Test ROS RMSE for lm: 0.0005132085908652346\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.912822839233489\n",
      "Test ROS RMSE for rf: 0.00045548818212972866\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.7808558069457425\n",
      "Test ROS RMSE for xgb: 0.00043885372111460077\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.1612224803858964\n",
      "Test ROS RMSE for lm: 0.0005102190780754649\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.937279926051348\n",
      "Test ROS RMSE for rf: 0.0004579168859371577\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.8364426203515243\n",
      "Test ROS RMSE for xgb: 0.00044270881245492895\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.217262099019969\n",
      "Test ROS RMSE for lm: 0.0005108828140963967\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.9939488726776844\n",
      "Test ROS RMSE for rf: 0.00046809069127107055\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.86918347988035\n",
      "Test ROS RMSE for xgb: 0.00044206658034592883\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.2794934292689475\n",
      "Test ROS RMSE for lm: 0.0005140789898148799\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.0518692372038227\n",
      "Test ROS RMSE for rf: 0.0004713272309938773\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.036998131006135\n",
      "Test ROS RMSE for xgb: 0.000478967216941328\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.205571667154486\n",
      "Test ROS RMSE for lm: 0.0005770418005964919\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.0244874367935908\n",
      "Test ROS RMSE for rf: 0.0004649146804237233\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-09\n",
      "Total observations: (80369, 17)\n",
      "Number of Training Observations: 59671\n",
      "Number of Training Locations: 91\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-09-01 00:03:00', '2023-09-28 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1102\n",
      "Number of Test Locations: 23\n",
      "Time range Test: ('2023-09-29 00:01:00', '2023-09-30 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.5006983956672975\n",
      "Test ROS RMSE for xgb: 0.00041609864693678035\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.252881436134063\n",
      "Test ROS RMSE for lm: 0.0006136288303472804\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8407668892869076\n",
      "Test ROS RMSE for rf: 0.0005003165253628949\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.449115456934788\n",
      "Test ROS RMSE for xgb: 0.0004101491364738526\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.19277553209458\n",
      "Test ROS RMSE for lm: 0.0006016963200247326\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.7624914565973007\n",
      "Test ROS RMSE for rf: 0.0004894861629437918\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.570164515260131\n",
      "Test ROS RMSE for xgb: 0.0004137895583598302\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0568314246951824\n",
      "Test ROS RMSE for lm: 0.0005705593829920592\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8342618932091046\n",
      "Test ROS RMSE for rf: 0.0004865904585752856\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.4844044804028664\n",
      "Test ROS RMSE for xgb: 0.0004030743609401541\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.9767270865094937\n",
      "Test ROS RMSE for lm: 0.0005435591177003675\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.725959461316078\n",
      "Test ROS RMSE for rf: 0.00047355765310321576\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.630082841391191\n",
      "Test ROS RMSE for xgb: 0.00040915933088304425\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.9701809156025134\n",
      "Test ROS RMSE for lm: 0.0005230008604215277\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.7351475333482216\n",
      "Test ROS RMSE for rf: 0.00046659105873645323\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.6164387482586546\n",
      "Test ROS RMSE for xgb: 0.0004050192926598671\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0382843329760054\n",
      "Test ROS RMSE for lm: 0.0005101950763420687\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.7728523498040305\n",
      "Test ROS RMSE for rf: 0.00046032253467593676\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.775250863790239\n",
      "Test ROS RMSE for xgb: 0.00041436762839866504\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.1634935382582374\n",
      "Test ROS RMSE for lm: 0.0005049203297831183\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.847670677775996\n",
      "Test ROS RMSE for rf: 0.00045842791217608913\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.810781861240572\n",
      "Test ROS RMSE for xgb: 0.0004129318192641348\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.322377963463113\n",
      "Test ROS RMSE for lm: 0.0005054990448913311\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.83703856159852\n",
      "Test ROS RMSE for rf: 0.0004512525576068289\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.0123964039402296\n",
      "Test ROS RMSE for xgb: 0.0004260194827610429\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.4929065406207758\n",
      "Test ROS RMSE for lm: 0.0005099730143332348\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.959449058980919\n",
      "Test ROS RMSE for rf: 0.000455870166928012\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.169867468391648\n",
      "Test ROS RMSE for xgb: 0.0004373072331680289\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.660032652737987\n",
      "Test ROS RMSE for lm: 0.0005166753371451304\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.1696756507607584\n",
      "Test ROS RMSE for rf: 0.000466915555256139\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.2583407893674483\n",
      "Test ROS RMSE for xgb: 0.00044735805783666116\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.8174717506826013\n",
      "Test ROS RMSE for lm: 0.0005245611799335657\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.2714273584211333\n",
      "Test ROS RMSE for rf: 0.00047177722988901347\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.450756876164786\n",
      "Test ROS RMSE for xgb: 0.0004014627972246899\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.997623152254906\n",
      "Test ROS RMSE for lm: 0.0005517562705987679\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.7800975438152538\n",
      "Test ROS RMSE for rf: 0.0004785109172276489\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-10\n",
      "Total observations: (80498, 17)\n",
      "Number of Training Observations: 60857\n",
      "Number of Training Locations: 92\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-10-01 00:01:00', '2023-10-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 960\n",
      "Number of Test Locations: 20\n",
      "Time range Test: ('2023-10-30 00:03:00', '2023-10-31 23:56:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.9715662948443153\n",
      "Test ROS RMSE for xgb: 0.0003273281345841534\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.9894111029851396\n",
      "Test ROS RMSE for lm: 0.0003683037555873929\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.0846895488354957\n",
      "Test ROS RMSE for rf: 0.00034029944520097566\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.9223487789499876\n",
      "Test ROS RMSE for xgb: 0.000325291664298488\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.9815391722855513\n",
      "Test ROS RMSE for lm: 0.00036756570833755596\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.0151734862210677\n",
      "Test ROS RMSE for rf: 0.0003231419783471037\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.9424249973134984\n",
      "Test ROS RMSE for xgb: 0.00031586591197961127\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.9920673390419052\n",
      "Test ROS RMSE for lm: 0.0003686365698989704\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.118984747885959\n",
      "Test ROS RMSE for rf: 0.0003369435247341441\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.8527099775156355\n",
      "Test ROS RMSE for xgb: 0.00030966436567695445\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0616710085325582\n",
      "Test ROS RMSE for lm: 0.0003759141494124088\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.2234825115989496\n",
      "Test ROS RMSE for rf: 0.0003520983575983785\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.9194257684582934\n",
      "Test ROS RMSE for xgb: 0.0003112003138965065\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.1978840118785965\n",
      "Test ROS RMSE for lm: 0.00039069122089045716\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.475604680966402\n",
      "Test ROS RMSE for rf: 0.0003923099710028555\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.1201077149860597\n",
      "Test ROS RMSE for xgb: 0.0003284032662362151\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.393236236717784\n",
      "Test ROS RMSE for lm: 0.00041281886900552706\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.5101347265716045\n",
      "Test ROS RMSE for rf: 0.00039627673024321793\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.029648114860911\n",
      "Test ROS RMSE for xgb: 0.00031764141620276953\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.6290439882083665\n",
      "Test ROS RMSE for lm: 0.0004409896796094224\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.749681870046771\n",
      "Test ROS RMSE for rf: 0.0004300675134059797\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.07106485902602\n",
      "Test ROS RMSE for xgb: 0.00032452761716770303\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.8864724506437187\n",
      "Test ROS RMSE for lm: 0.0004736952129470402\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.8880977609025904\n",
      "Test ROS RMSE for rf: 0.00044913593281684636\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.2378415386824613\n",
      "Test ROS RMSE for xgb: 0.00034222532058064144\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.146968786880507\n",
      "Test ROS RMSE for lm: 0.0005090723425192947\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.9964304735233576\n",
      "Test ROS RMSE for rf: 0.0004706538665970261\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.346750794446782\n",
      "Test ROS RMSE for xgb: 0.0003527223632326252\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.39727448802849\n",
      "Test ROS RMSE for lm: 0.0005454682942734865\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.03457704882498\n",
      "Test ROS RMSE for rf: 0.00048471804109231394\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.34115749293143\n",
      "Test ROS RMSE for xgb: 0.00035131860305398954\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.6322120513719165\n",
      "Test ROS RMSE for lm: 0.0005819887993243282\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.155265502677292\n",
      "Test ROS RMSE for rf: 0.0004946183372821505\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.0088747980468344\n",
      "Test ROS RMSE for xgb: 0.0003243608789528224\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0192340675049394\n",
      "Test ROS RMSE for lm: 0.00036989649591931303\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.3199505358762544\n",
      "Test ROS RMSE for rf: 0.00037409185154996727\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-11\n",
      "Total observations: (71429, 17)\n",
      "Number of Training Observations: 52100\n",
      "Number of Training Locations: 84\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-11-01 00:03:00', '2023-11-28 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1056\n",
      "Number of Test Locations: 22\n",
      "Time range Test: ('2023-11-29 00:11:00', '2023-11-30 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.512043435297948\n",
      "Test ROS RMSE for xgb: 0.0003698031013879575\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.515441034202196\n",
      "Test ROS RMSE for lm: 0.00037318062937377865\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.5784418232138377\n",
      "Test ROS RMSE for rf: 0.0003691667768180192\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.5655950059118116\n",
      "Test ROS RMSE for xgb: 0.0003742775341304883\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.485550324345778\n",
      "Test ROS RMSE for lm: 0.00036841816883695215\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.4889633667847137\n",
      "Test ROS RMSE for rf: 0.0003584336852275587\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.388979089568752\n",
      "Test ROS RMSE for xgb: 0.00036051964260254914\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.4233323936620206\n",
      "Test ROS RMSE for lm: 0.0003576377297961851\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.3448530371221596\n",
      "Test ROS RMSE for rf: 0.00034555397771466814\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.378584022282478\n",
      "Test ROS RMSE for xgb: 0.000356452469665773\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.3864196779509217\n",
      "Test ROS RMSE for lm: 0.0003496328789140135\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.3308615348669517\n",
      "Test ROS RMSE for rf: 0.0003424130171507168\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.3089190442817826\n",
      "Test ROS RMSE for xgb: 0.00035233279870829846\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.3730454890722523\n",
      "Test ROS RMSE for lm: 0.00034420117000727446\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.2752481257508577\n",
      "Test ROS RMSE for rf: 0.00033919555389992076\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.2281845909378206\n",
      "Test ROS RMSE for xgb: 0.0003414391756518876\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.380930004576676\n",
      "Test ROS RMSE for lm: 0.00034124275245845797\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.241411456393547\n",
      "Test ROS RMSE for rf: 0.00033685764211654204\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.151308045288868\n",
      "Test ROS RMSE for xgb: 0.00033224800257670404\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.406899165612657\n",
      "Test ROS RMSE for lm: 0.000340637894618237\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.194113660210026\n",
      "Test ROS RMSE for rf: 0.00032792192650977977\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.105217026886164\n",
      "Test ROS RMSE for xgb: 0.00032522254006233736\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.4479325580507427\n",
      "Test ROS RMSE for lm: 0.0003422672899173336\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.2011659503887415\n",
      "Test ROS RMSE for rf: 0.00033556925476350144\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.0764417438983496\n",
      "Test ROS RMSE for xgb: 0.0003197541054857587\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.5008718546672095\n",
      "Test ROS RMSE for lm: 0.0003460086175616213\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.152021503097663\n",
      "Test ROS RMSE for rf: 0.00032428484776714364\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.0070103265755823\n",
      "Test ROS RMSE for xgb: 0.0003119105711992476\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.562701581067193\n",
      "Test ROS RMSE for lm: 0.00035168595919030907\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.160061585656297\n",
      "Test ROS RMSE for rf: 0.0003334739718583495\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.036271607076875\n",
      "Test ROS RMSE for xgb: 0.00031208800692996834\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.6315296178647327\n",
      "Test ROS RMSE for lm: 0.00035917104771411584\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.160853177851361\n",
      "Test ROS RMSE for rf: 0.00033628597878481147\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.4344718301673955\n",
      "Test ROS RMSE for xgb: 0.00037158636342202677\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.411702099275371\n",
      "Test ROS RMSE for lm: 0.00035481930245078727\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.3713634829714927\n",
      "Test ROS RMSE for rf: 0.00035067418512390165\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2023-12\n",
      "Total observations: (71049, 17)\n",
      "Number of Training Observations: 53177\n",
      "Number of Training Locations: 80\n",
      "Number of Features: 16\n",
      "Time range Train: ('2023-12-01 00:03:00', '2023-12-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 911\n",
      "Number of Test Locations: 19\n",
      "Time range Test: ('2023-12-30 00:07:00', '2023-12-31 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.7422870204912515\n",
      "Test ROS RMSE for xgb: 0.0007129916252212483\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.34732023759736\n",
      "Test ROS RMSE for lm: 0.0006609534409630178\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.658570454011121\n",
      "Test ROS RMSE for rf: 0.0007056356037373278\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.9239109427244125\n",
      "Test ROS RMSE for xgb: 0.000732432608592799\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.344982531050284\n",
      "Test ROS RMSE for lm: 0.0006607543375854613\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.669978878891445\n",
      "Test ROS RMSE for rf: 0.0007062371935030753\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.300973415905987\n",
      "Test ROS RMSE for xgb: 0.0006643923425221512\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.354039440823768\n",
      "Test ROS RMSE for lm: 0.0006618811229272029\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.3686501364252965\n",
      "Test ROS RMSE for rf: 0.0006711444389045893\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.639908222583877\n",
      "Test ROS RMSE for xgb: 0.0007004848990266214\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.382393725515705\n",
      "Test ROS RMSE for lm: 0.0006648653333249055\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.348260632599485\n",
      "Test ROS RMSE for rf: 0.0006623508493038216\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.418565369423333\n",
      "Test ROS RMSE for xgb: 0.0006752945430069104\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.427110106238002\n",
      "Test ROS RMSE for lm: 0.000669290979898111\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.372169175284292\n",
      "Test ROS RMSE for rf: 0.0006616892174373308\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.2132319548546615\n",
      "Test ROS RMSE for xgb: 0.0006483530078527466\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.484675228195309\n",
      "Test ROS RMSE for lm: 0.0006748255831468258\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.410703180438361\n",
      "Test ROS RMSE for rf: 0.0006668373924367225\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.170940916905087\n",
      "Test ROS RMSE for xgb: 0.0006425354248251943\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.551122540530377\n",
      "Test ROS RMSE for lm: 0.0006811498590552597\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.462493364131181\n",
      "Test ROS RMSE for rf: 0.0006695620309150877\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.159492342442633\n",
      "Test ROS RMSE for xgb: 0.0006382299169113504\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.623439080794537\n",
      "Test ROS RMSE for lm: 0.000688044491225712\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.45079455674624\n",
      "Test ROS RMSE for rf: 0.000666798708678066\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.276333426207089\n",
      "Test ROS RMSE for xgb: 0.0006503383764831885\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.6984494531951295\n",
      "Test ROS RMSE for lm: 0.0006952740791994964\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.4935797669383\n",
      "Test ROS RMSE for rf: 0.0006678515928213443\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.284639735674163\n",
      "Test ROS RMSE for xgb: 0.0006469748288367011\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.773695653220875\n",
      "Test ROS RMSE for lm: 0.0007026699632143535\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.553067512636243\n",
      "Test ROS RMSE for rf: 0.0006738977355338672\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.381834274926721\n",
      "Test ROS RMSE for xgb: 0.0006574844858505335\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.848309996901492\n",
      "Test ROS RMSE for lm: 0.0007102078250039829\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.622143326089902\n",
      "Test ROS RMSE for rf: 0.0006804244113980958\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.92048179139266\n",
      "Test ROS RMSE for xgb: 0.0006221807276572844\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.361834245144256\n",
      "Test ROS RMSE for lm: 0.0006626007819329138\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.3358806595705515\n",
      "Test ROS RMSE for rf: 0.0006657138014007197\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2024-01\n",
      "Total observations: (68448, 17)\n",
      "Number of Training Observations: 50058\n",
      "Number of Training Locations: 79\n",
      "Number of Features: 16\n",
      "Time range Train: ('2024-01-01 00:03:00', '2024-01-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 959\n",
      "Number of Test Locations: 20\n",
      "Time range Test: ('2024-01-30 00:06:00', '2024-01-31 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.2209262130201397\n",
      "Test ROS RMSE for xgb: 0.00038680569135682936\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.081905610762954\n",
      "Test ROS RMSE for lm: 0.0003832781331654156\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.988153972155176\n",
      "Test ROS RMSE for rf: 0.000472899160009874\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.1773366707239217\n",
      "Test ROS RMSE for xgb: 0.00038128002889691986\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.9890606555815005\n",
      "Test ROS RMSE for lm: 0.0003731235773899582\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.6531899003249824\n",
      "Test ROS RMSE for rf: 0.00044313926475005613\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.1875761445069153\n",
      "Test ROS RMSE for xgb: 0.0003789089097074731\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.815378511073087\n",
      "Test ROS RMSE for lm: 0.0003526533078172204\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.8297885019907536\n",
      "Test ROS RMSE for rf: 0.0004491035242506595\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.060671085783621\n",
      "Test ROS RMSE for xgb: 0.0003704976087995107\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.736829368403489\n",
      "Test ROS RMSE for lm: 0.0003408959047266606\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.6425169668384862\n",
      "Test ROS RMSE for rf: 0.00043295203213909885\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.8639030499327993\n",
      "Test ROS RMSE for xgb: 0.00035497440633628\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.732316414415943\n",
      "Test ROS RMSE for lm: 0.00033627280948229227\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.108284100978742\n",
      "Test ROS RMSE for rf: 0.0003822502019389653\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.7603860153430513\n",
      "Test ROS RMSE for xgb: 0.00033350904693484724\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.779779930824896\n",
      "Test ROS RMSE for lm: 0.00033704736795178676\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.745338036201726\n",
      "Test ROS RMSE for rf: 0.0003500503807633751\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.611582510777098\n",
      "Test ROS RMSE for xgb: 0.00031564199228246406\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.8585774162502595\n",
      "Test ROS RMSE for lm: 0.000341394995167057\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.605466405797527\n",
      "Test ROS RMSE for rf: 0.0003325707473421512\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.679710156852925\n",
      "Test ROS RMSE for xgb: 0.00031965295818454947\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.953807938297427\n",
      "Test ROS RMSE for lm: 0.00034785333046105665\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.6669891954278806\n",
      "Test ROS RMSE for rf: 0.0003318064811002711\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.6758718739833576\n",
      "Test ROS RMSE for xgb: 0.0003172210356330327\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.0548320346616546\n",
      "Test ROS RMSE for lm: 0.0003553524306752014\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.714591950584768\n",
      "Test ROS RMSE for rf: 0.00033175313001592284\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.719606015665378\n",
      "Test ROS RMSE for xgb: 0.00031806472944244244\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.155141011780733\n",
      "Test ROS RMSE for lm: 0.0003632174117297432\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.7691496612583353\n",
      "Test ROS RMSE for rf: 0.0003331733668310184\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.7114962340991164\n",
      "Test ROS RMSE for xgb: 0.000315095372773536\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.252357075979966\n",
      "Test ROS RMSE for lm: 0.00037116905650624085\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 2.8805665762754242\n",
      "Test ROS RMSE for rf: 0.0003397800507987164\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 2.948156794750831\n",
      "Test ROS RMSE for xgb: 0.00036091972699728634\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 2.724133455001307\n",
      "Test ROS RMSE for lm: 0.00034005528029089983\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.351326862698163\n",
      "Test ROS RMSE for rf: 0.00040969702826378594\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2024-02\n",
      "Total observations: (65205, 17)\n",
      "Number of Training Observations: 49053\n",
      "Number of Training Locations: 82\n",
      "Number of Features: 16\n",
      "Time range Train: ('2024-02-01 00:02:00', '2024-02-27 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 893\n",
      "Number of Test Locations: 20\n",
      "Time range Test: ('2024-02-28 00:06:00', '2024-02-29 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.853670257508887\n",
      "Test ROS RMSE for xgb: 0.001016154123039299\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.37188041518529\n",
      "Test ROS RMSE for lm: 0.0009037665827282258\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.794194965514337\n",
      "Test ROS RMSE for rf: 0.0010364567755312569\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.715641928578278\n",
      "Test ROS RMSE for xgb: 0.0009953382707524746\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.4261224040233555\n",
      "Test ROS RMSE for lm: 0.0009024693994255535\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.781144181859416\n",
      "Test ROS RMSE for rf: 0.001032986634793048\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.758729377223326\n",
      "Test ROS RMSE for xgb: 0.0009967147236019864\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.588413196331831\n",
      "Test ROS RMSE for lm: 0.0009037620398522372\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.0786038193443\n",
      "Test ROS RMSE for rf: 0.0010703334187604878\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.6626036091766485\n",
      "Test ROS RMSE for xgb: 0.0009824762809040244\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.761627796746656\n",
      "Test ROS RMSE for lm: 0.0009132130781040591\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.44165165040405\n",
      "Test ROS RMSE for rf: 0.0011073816613392494\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.672883005835537\n",
      "Test ROS RMSE for xgb: 0.00099101570154296\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.932158975988196\n",
      "Test ROS RMSE for lm: 0.0009287391454923024\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.643283428103876\n",
      "Test ROS RMSE for rf: 0.0011310904631056664\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.08538704537075\n",
      "Test ROS RMSE for xgb: 0.0010789488719454498\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.089173946840153\n",
      "Test ROS RMSE for lm: 0.0009468564585131398\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.849845396773633\n",
      "Test ROS RMSE for rf: 0.0011741504872581601\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.115918122681114\n",
      "Test ROS RMSE for xgb: 0.0010635071384780535\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.227400575377973\n",
      "Test ROS RMSE for lm: 0.0009648957913788446\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.984051098686017\n",
      "Test ROS RMSE for rf: 0.0011972690588356065\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.126998194024104\n",
      "Test ROS RMSE for xgb: 0.0010661068923418832\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.347372496069939\n",
      "Test ROS RMSE for lm: 0.0009816834883249752\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.793800923585696\n",
      "Test ROS RMSE for rf: 0.001151550000863543\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.8620522045778225\n",
      "Test ROS RMSE for xgb: 0.0010243953221380083\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.450518345490914\n",
      "Test ROS RMSE for lm: 0.0009967757616551355\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 9.051844863485135\n",
      "Test ROS RMSE for rf: 0.0012051553238888787\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.792373081065896\n",
      "Test ROS RMSE for xgb: 0.0010035466853466318\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.539481282748077\n",
      "Test ROS RMSE for lm: 0.0010102446117988481\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 9.02196299625224\n",
      "Test ROS RMSE for rf: 0.001199125250322297\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.8120965676684575\n",
      "Test ROS RMSE for xgb: 0.0010146066985309463\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.617912166108319\n",
      "Test ROS RMSE for lm: 0.0010224966744047602\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.512195795381531\n",
      "Test ROS RMSE for rf: 0.0011200353533842027\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 6.939319590659626\n",
      "Test ROS RMSE for xgb: 0.0008979460776058873\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.765266359743614\n",
      "Test ROS RMSE for lm: 0.0009124943816605053\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.415482200811269\n",
      "Test ROS RMSE for rf: 0.0011008741010784537\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2024-03\n",
      "Total observations: (70714, 17)\n",
      "Number of Training Observations: 52642\n",
      "Number of Training Locations: 81\n",
      "Number of Features: 16\n",
      "Time range Train: ('2024-03-01 00:03:00', '2024-03-29 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 955\n",
      "Number of Test Locations: 20\n",
      "Time range Test: ('2024-03-30 00:08:00', '2024-03-31 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 6.902232284403287\n",
      "Test ROS RMSE for xgb: 0.0009037411701576915\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.382909692756863\n",
      "Test ROS RMSE for lm: 0.0008469631173096405\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 6.895583787408739\n",
      "Test ROS RMSE for rf: 0.0009144260063524214\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.072553946521546\n",
      "Test ROS RMSE for xgb: 0.0009219338552612496\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.383813212300504\n",
      "Test ROS RMSE for lm: 0.0008485655619225516\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 6.869248804344626\n",
      "Test ROS RMSE for rf: 0.0009059543270975481\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.276883962933358\n",
      "Test ROS RMSE for xgb: 0.0009444814062847835\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.4662840932449965\n",
      "Test ROS RMSE for lm: 0.0008593803849677439\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.103373431674279\n",
      "Test ROS RMSE for rf: 0.0009291637804235601\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.362291811577738\n",
      "Test ROS RMSE for xgb: 0.0009515245824849277\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.638664353752704\n",
      "Test ROS RMSE for lm: 0.000877350341432653\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.3111025598489086\n",
      "Test ROS RMSE for rf: 0.0009490925905424359\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.635321097668394\n",
      "Test ROS RMSE for xgb: 0.0009758592319500125\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.868006462066928\n",
      "Test ROS RMSE for lm: 0.0008997683495000172\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.492659346632201\n",
      "Test ROS RMSE for rf: 0.0009677697086776767\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.913140166686705\n",
      "Test ROS RMSE for xgb: 0.0010071814299985025\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.123292041768046\n",
      "Test ROS RMSE for lm: 0.0009239342340387551\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.696053879861137\n",
      "Test ROS RMSE for rf: 0.000987236432487375\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.082587772701576\n",
      "Test ROS RMSE for xgb: 0.0010258335238145498\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.381049080978118\n",
      "Test ROS RMSE for lm: 0.0009477940292649568\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.7885183452795514\n",
      "Test ROS RMSE for rf: 0.0009925363759054385\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.259663397080049\n",
      "Test ROS RMSE for xgb: 0.0010422848855237642\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.629408634014618\n",
      "Test ROS RMSE for lm: 0.0009704583269265896\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.981014011397238\n",
      "Test ROS RMSE for rf: 0.0010102242280032809\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.33131403473194\n",
      "Test ROS RMSE for xgb: 0.0010436622237827964\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 7.860596650733606\n",
      "Test ROS RMSE for lm: 0.0009914543540039734\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.101873357269968\n",
      "Test ROS RMSE for rf: 0.0010158265536298668\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.368029779662619\n",
      "Test ROS RMSE for xgb: 0.0010459288765891574\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 8.071797657916203\n",
      "Test ROS RMSE for lm: 0.00101074409360644\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.243458986245708\n",
      "Test ROS RMSE for rf: 0.0010277614732165546\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 8.450934592620943\n",
      "Test ROS RMSE for xgb: 0.0010463875776010763\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 8.265244207027978\n",
      "Test ROS RMSE for lm: 0.0010286848635672015\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 8.357863726412146\n",
      "Test ROS RMSE for rf: 0.0010374460066198466\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 7.2091486083694045\n",
      "Test ROS RMSE for xgb: 0.0009362302310813516\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.638237450478589\n",
      "Test ROS RMSE for lm: 0.0008770691877582583\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 7.236728957737674\n",
      "Test ROS RMSE for rf: 0.000941884658939253\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2024-04\n",
      "Total observations: (74101, 17)\n",
      "Number of Training Observations: 55204\n",
      "Number of Training Locations: 85\n",
      "Number of Features: 16\n",
      "Time range Train: ('2024-04-01 00:01:00', '2024-04-28 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1025\n",
      "Number of Test Locations: 22\n",
      "Time range Test: ('2024-04-28 23:59:00', '2024-04-30 23:59:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.6724612977845372\n",
      "Test ROS RMSE for xgb: 0.0004959841485557237\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.365245069459635\n",
      "Test ROS RMSE for lm: 0.0004889084061830156\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.396426307800081\n",
      "Test ROS RMSE for rf: 0.00045057431929200286\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.647039224097595\n",
      "Test ROS RMSE for xgb: 0.0004918929759919661\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.3822394938194775\n",
      "Test ROS RMSE for lm: 0.0004895478391734706\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.2888314367450793\n",
      "Test ROS RMSE for rf: 0.00043336021582814104\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.475608135545207\n",
      "Test ROS RMSE for xgb: 0.00047214016505267304\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.503729066561514\n",
      "Test ROS RMSE for lm: 0.0004957923179064908\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.1937425442517693\n",
      "Test ROS RMSE for rf: 0.00042308800200866544\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.533504285536576\n",
      "Test ROS RMSE for xgb: 0.0004773791741408124\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.707050291752482\n",
      "Test ROS RMSE for lm: 0.0005093425835425441\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.150440498438081\n",
      "Test ROS RMSE for rf: 0.0004245728458203069\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.54892222931854\n",
      "Test ROS RMSE for xgb: 0.00048200944979359884\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.962147459517656\n",
      "Test ROS RMSE for lm: 0.000530364750937903\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.2878267155910956\n",
      "Test ROS RMSE for rf: 0.0004256186160491345\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.349961234486586\n",
      "Test ROS RMSE for xgb: 0.00046724153134334077\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.239258093904311\n",
      "Test ROS RMSE for lm: 0.0005574029345524959\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.5432208992695124\n",
      "Test ROS RMSE for rf: 0.0004634320780840949\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.243911852325487\n",
      "Test ROS RMSE for xgb: 0.00045413120199778415\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.5136823991857815\n",
      "Test ROS RMSE for lm: 0.0005882188664286198\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.701163240691158\n",
      "Test ROS RMSE for rf: 0.0004853567368613394\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.315251760335768\n",
      "Test ROS RMSE for xgb: 0.000469667688563527\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 4.771843812873419\n",
      "Test ROS RMSE for lm: 0.0006210156680386287\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.75117894882007\n",
      "Test ROS RMSE for rf: 0.0005012880164879712\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.267317704302413\n",
      "Test ROS RMSE for xgb: 0.0004541671007229412\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.004879614319247\n",
      "Test ROS RMSE for lm: 0.0006540872079698871\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.884849134104902\n",
      "Test ROS RMSE for rf: 0.0005061512686750712\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.4405602457067253\n",
      "Test ROS RMSE for xgb: 0.00047472968033547807\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.210136151400199\n",
      "Test ROS RMSE for lm: 0.0006862271365354613\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.298930922156406\n",
      "Test ROS RMSE for rf: 0.0005671630186877314\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.483163350541793\n",
      "Test ROS RMSE for xgb: 0.0004729430084106481\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.390709080787091\n",
      "Test ROS RMSE for lm: 0.0007170559584340009\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 4.30321952032267\n",
      "Test ROS RMSE for rf: 0.0005615868361564662\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 3.395188216608294\n",
      "Test ROS RMSE for xgb: 0.00047213037741154973\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 3.643181872139184\n",
      "Test ROS RMSE for lm: 0.0004997416036160884\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 3.168714183566357\n",
      "Test ROS RMSE for rf: 0.00043384886673300684\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Splitting data for month: 2024-05\n",
      "Total observations: (35479, 17)\n",
      "Number of Training Observations: 24171\n",
      "Number of Training Locations: 87\n",
      "Number of Features: 16\n",
      "Time range Train: ('2024-05-01 00:01:00', '2024-05-12 23:58:00')\n",
      "----------\n",
      "Number of Test Observations: 1054\n",
      "Number of Test Locations: 22\n",
      "Time range Test: ('2024-05-13 00:07:00', '2024-05-14 23:58:00')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: rss\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.761018348500019\n",
      "Test ROS RMSE for xgb: 0.0006462406870985772\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.253908314909605\n",
      "Test ROS RMSE for lm: 0.0006918141501503951\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.186454875334661\n",
      "Test ROS RMSE for rf: 0.0006790125951242667\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.01\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.7968659475001925\n",
      "Test ROS RMSE for xgb: 0.0006510239039001814\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.303744801076018\n",
      "Test ROS RMSE for lm: 0.0006963969386045954\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.2139277095262\n",
      "Test ROS RMSE for rf: 0.0006810416704674424\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0367\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.8057334769466635\n",
      "Test ROS RMSE for xgb: 0.000646865824326791\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.459455262021547\n",
      "Test ROS RMSE for lm: 0.0007111024834577412\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.371466923211155\n",
      "Test ROS RMSE for rf: 0.0006966804964753033\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.0633\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.919086035005115\n",
      "Test ROS RMSE for xgb: 0.0006572640602277054\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.640226807582501\n",
      "Test ROS RMSE for lm: 0.000728544348018657\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.506429698621974\n",
      "Test ROS RMSE for rf: 0.0007095150850278383\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.09\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.093053774336617\n",
      "Test ROS RMSE for xgb: 0.0006699195416859325\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.837388189946156\n",
      "Test ROS RMSE for lm: 0.0007479394802806998\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.6115583293630955\n",
      "Test ROS RMSE for rf: 0.0007210498116328363\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1167\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.331936512138773\n",
      "Test ROS RMSE for xgb: 0.0006909212574425118\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.039990767484384\n",
      "Test ROS RMSE for lm: 0.0007684179571787505\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.671073814753771\n",
      "Test ROS RMSE for rf: 0.0007246495678992987\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1433\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.365528966636612\n",
      "Test ROS RMSE for xgb: 0.0006939616675810439\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.238296244039386\n",
      "Test ROS RMSE for lm: 0.0007892148782249318\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.862281292523302\n",
      "Test ROS RMSE for rf: 0.0007461365683995141\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.17\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.493181259640866\n",
      "Test ROS RMSE for xgb: 0.0007047432643229767\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.427249257385699\n",
      "Test ROS RMSE for lm: 0.0008099483223828721\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.905852630432911\n",
      "Test ROS RMSE for rf: 0.0007498043027505405\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.1967\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.626487476631726\n",
      "Test ROS RMSE for xgb: 0.0007154146879088693\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.602261283969249\n",
      "Test ROS RMSE for lm: 0.0008301634780097713\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 6.0606983704912905\n",
      "Test ROS RMSE for rf: 0.0007671271588076246\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.2233\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.801500526004395\n",
      "Test ROS RMSE for xgb: 0.0007312250014665679\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.76127529278543\n",
      "Test ROS RMSE for lm: 0.0008482601492536228\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 6.201261807203696\n",
      "Test ROS RMSE for rf: 0.0007813548377740739\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: exp_0.25\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 5.963435725548155\n",
      "Test ROS RMSE for xgb: 0.0007462856716627934\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 6.9056365852729185\n",
      "Test ROS RMSE for lm: 0.0008655685195674652\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 6.371429937427728\n",
      "Test ROS RMSE for rf: 0.0007948126338821189\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running models for loss func: ros\n",
      "Fitting xgb\n",
      "Training XGB with params: {'max_depth': 3, 'eta': 0.1, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'scale_pos_weight': 1, 'n_estimators': 100, 'gamma': 0.1}\n",
      "Predicting with XGB\n",
      "Test RMSE for xgb: 4.9336643900625194\n",
      "Test ROS RMSE for xgb: 0.0006553252747422971\n",
      "Fitting lm\n",
      "Training LM with params: {'fit_intercept': True}\n",
      "Predicting with LM\n",
      "Test RMSE for lm: 5.558396033798443\n",
      "Test ROS RMSE for lm: 0.0007210751264681662\n",
      "Fitting rf\n",
      "Training RF with params: {'n_estimators': 25, 'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.8, 'bootstrap': True, 'max_samples': None, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Predicting with RF\n",
      "Test RMSE for rf: 5.414522481518407\n",
      "Test ROS RMSE for rf: 0.0007010086121559899\n"
     ]
    }
   ],
   "source": [
    "# Get unique month and year combos in the data\n",
    "month_year = df.index.to_period('M').unique()\n",
    "print(month_year)\n",
    "reproducibility.set_seed(42)\n",
    "for my in month_year:\n",
    "    print(\"~\"*80)\n",
    "    month = my.month\n",
    "    year = my.year\n",
    "    print(f\"Splitting data for month: {my}\")\n",
    "    df_temp = df[(df.index.month == month) & (df.index.year == year)]\n",
    "    print(f\"Total observations: {df_temp.shape}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "        df_temp, \n",
    "        test_days = 2,\n",
    "        spatial_test_frac = 0.2,\n",
    "        verbose = True\n",
    "    )\n",
    "    X_train = X_train[cols]\n",
    "    X_test = X_test[cols]\n",
    "    for l in loss_dict:\n",
    "        print(\"~\"*50)\n",
    "        print(f\"Running models for loss func: {l}\")\n",
    "        if loss_dict[l]['w_func'] is not None:\n",
    "            weights = loss_dict[l]['w_func'](y_train)\n",
    "        else:\n",
    "            weights = None\n",
    "        # Reinitialize models dictionary to prevent multiple fitting iterations\n",
    "        # if True:\n",
    "        #     models = initialize_models()\n",
    "        for mod in models:\n",
    "            print(f\"Fitting {mod}\")\n",
    "            models[mod].fit(X_train, y_train, weights)\n",
    "            preds = models[mod].predict(X_test)\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test\"].append(rmse(preds, y_test))\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test_ROS\"].append(rmse(ros(preds), ros(y_test)))\n",
    "            print(f\"Test RMSE for {mod}: {rmse(preds, y_test)}\")\n",
    "            print(f\"Test ROS RMSE for {mod}: {rmse(ros(preds), ros(y_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b8c491b-454f-4a60-9a47-88ee116a8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vec = [*loss_dict.keys()]\n",
    "models_vec = [*models.keys()]\n",
    "df1 = pd.DataFrame(np.zeros((len(loss_vec), len(models_vec))), index=loss_vec, columns=models_vec)\n",
    "df2 = pd.DataFrame(np.zeros((len(loss_vec), len(models_vec))), index=loss_vec, columns=models_vec)\n",
    "\n",
    "for l in loss_dict:\n",
    "    for mod in loss_dict[l][\"errs\"]:\n",
    "        df1.loc[l, mod] = np.mean(loss_dict[l][\"errs\"][mod]['rmse_test'])\n",
    "        df2.loc[l, mod] = np.mean(loss_dict[l][\"errs\"][mod]['rmse_test_ROS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b86132f-57b4-49e3-a3f7-d5de85311d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb</th>\n",
       "      <th>lm</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rss</th>\n",
       "      <td>4.079988</td>\n",
       "      <td>4.047608</td>\n",
       "      <td>4.234905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.01</th>\n",
       "      <td>4.083878</td>\n",
       "      <td>4.035755</td>\n",
       "      <td>4.173229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.0367</th>\n",
       "      <td>4.024422</td>\n",
       "      <td>4.036180</td>\n",
       "      <td>4.202058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.0633</th>\n",
       "      <td>4.026695</td>\n",
       "      <td>4.079229</td>\n",
       "      <td>4.225711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.09</th>\n",
       "      <td>4.037405</td>\n",
       "      <td>4.159735</td>\n",
       "      <td>4.243354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.1167</th>\n",
       "      <td>4.089292</td>\n",
       "      <td>4.269798</td>\n",
       "      <td>4.293801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.1433</th>\n",
       "      <td>4.099779</td>\n",
       "      <td>4.399264</td>\n",
       "      <td>4.360429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.17</th>\n",
       "      <td>4.168534</td>\n",
       "      <td>4.539470</td>\n",
       "      <td>4.396971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.1967</th>\n",
       "      <td>4.215688</td>\n",
       "      <td>4.681931</td>\n",
       "      <td>4.505772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.2233</th>\n",
       "      <td>4.285725</td>\n",
       "      <td>4.820515</td>\n",
       "      <td>4.632466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.25</th>\n",
       "      <td>4.362344</td>\n",
       "      <td>4.952987</td>\n",
       "      <td>4.698051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ros</th>\n",
       "      <td>3.908752</td>\n",
       "      <td>4.065696</td>\n",
       "      <td>4.208656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 xgb        lm        rf\n",
       "rss         4.079988  4.047608  4.234905\n",
       "exp_0.01    4.083878  4.035755  4.173229\n",
       "exp_0.0367  4.024422  4.036180  4.202058\n",
       "exp_0.0633  4.026695  4.079229  4.225711\n",
       "exp_0.09    4.037405  4.159735  4.243354\n",
       "exp_0.1167  4.089292  4.269798  4.293801\n",
       "exp_0.1433  4.099779  4.399264  4.360429\n",
       "exp_0.17    4.168534  4.539470  4.396971\n",
       "exp_0.1967  4.215688  4.681931  4.505772\n",
       "exp_0.2233  4.285725  4.820515  4.632466\n",
       "exp_0.25    4.362344  4.952987  4.698051\n",
       "ros         3.908752  4.065696  4.208656"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de83836e-ddee-43ed-9f11-8c4ff5a92725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb</th>\n",
       "      <th>lm</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rss</th>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.01</th>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.0367</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.0633</th>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.09</th>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.1167</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.1433</th>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.17</th>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.1967</th>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.2233</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_0.25</th>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ros</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 xgb        lm        rf\n",
       "rss         0.000546  0.000579  0.000574\n",
       "exp_0.01    0.000546  0.000576  0.000565\n",
       "exp_0.0367  0.000537  0.000570  0.000566\n",
       "exp_0.0633  0.000536  0.000568  0.000566\n",
       "exp_0.09    0.000536  0.000571  0.000567\n",
       "exp_0.1167  0.000543  0.000577  0.000573\n",
       "exp_0.1433  0.000541  0.000586  0.000580\n",
       "exp_0.17    0.000548  0.000598  0.000580\n",
       "exp_0.1967  0.000549  0.000611  0.000592\n",
       "exp_0.2233  0.000553  0.000624  0.000606\n",
       "exp_0.25    0.000560  0.000639  0.000608\n",
       "ros         0.000526  0.000568  0.000566"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c4ec8d-b34b-4cd6-803f-899b69718d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test RMSE by Loss Function - Linear Regression')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df1.index, df1[\"lm\"])\n",
    "plt.xlabel('Loss Function')\n",
    "plt.ylabel('RMSE Test Data')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Test RMSE by Loss Function - Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd7e384c-a4f4-4920-b03f-c239eeead237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(models_vec) # number of rows of subplots\n",
    "fig, axes = plt.subplots(N, 2, figsize=(10, 5*N))\n",
    "for i in range(0, len(models_vec)):\n",
    "    mod = models_vec[i]\n",
    "    # Access the subplot at row i, column 0\n",
    "    ax1 = axes[i, 0]\n",
    "    ax1.scatter(df1.index, df1[mod])\n",
    "    ax1.tick_params(axis='x', rotation=90)\n",
    "    ax1.set_title(f'Test RMSE - Model {mod}')\n",
    "\n",
    "    # Access the subplot at row i, column 1\n",
    "    ax2 = axes[i, 1]\n",
    "    ax2.scatter(df2.index, df2[mod])\n",
    "    ax2.tick_params(axis='x', rotation=90)\n",
    "    ax2.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    ax2.set_title(f'Test RMSE on ROS - Model {mod}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337e1e1-f8ac-415c-9cb4-578b0d9b880d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc0226-4903-45e8-8ef3-06f28602b62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
