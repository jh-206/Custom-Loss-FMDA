{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fe853-c3ab-481b-9470-b9b7f5f9c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "# Custom modules\n",
    "sys.path.append(osp.join(os.getcwd(),\"src\")) # Add src subdirectory to python path\n",
    "from data_funcs import synthetic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e1147-46c5-497b-a3a0-49a653889559",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Table of Contents and Define key terms\n",
    "    * Residual sum of squares RSS\n",
    "* Figure labeling\n",
    "* Is it ok to use bullet points and notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f9289-2126-4032-ba80-dcceda99b231",
   "metadata": {},
   "source": [
    "# Custom Loss Functions for Fuel Moisture Models\n",
    "\n",
    "*Author:* Jonathon Hirschi\n",
    "\n",
    "[Fuel moisture content](https://www.ncei.noaa.gov/access/monitoring/dyk/deadfuelmoisture) is a measure of the water content of burnable materials. A loss function is intended to measure the fitting accuracy of a statistical model.\n",
    "\n",
    "The purpose of this notebook is to discuss training fuel moisture models with various loss functions to try to account for the nonlinear effect of fuel moisture on wildfire rate of spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95fa10-9887-4668-a6ee-fd867acb99d0",
   "metadata": {},
   "source": [
    "## Example with Weighted Least Squares\n",
    "\n",
    "To illustrate the effect of changing loss functions, consider a simple linear model with one predictor for $n$ samples:\n",
    "\n",
    "$$f(x_i, \\pmb\\beta) = \\beta_0 + \\beta_1 x_i, \\text{ for }i=1,..., n$$\n",
    "\n",
    "Ordinary least squares (OLS) is the most basic method of estimating the $\\beta$ parameter values. The method minimizes the residual sum of squares (RSS), the loss function in this case. Equal weight is given to each residual value in the loss function,\n",
    "\n",
    "$$r_i = y_i - f(x_i, \\pmb \\beta)$$\n",
    "\n",
    "$$\\pmb{\\hat\\beta_{OLS}} = argmin_\\beta \\sum_{i=1}^n r_i^2$$\n",
    "\n",
    "Weighted least squares minimizes the weighted residual sum of squares, with a weight $w_i$ applied to each residual value. In principle, the weights could come from anywhere. \n",
    "\n",
    "$$\\pmb{\\hat\\beta_{W}} = argmin_\\beta \\sum_{i=1}^n w_ir_i^2$$\n",
    "\n",
    "In the following example, the OLS model for simulated data is compared to two different weighting schemes. In both cases, the weights come from normal distributions centered at the observed mean of the response value, but one has a large variance and the other has a much smaller variance. In this formulation of weights, as the variance of the normal distribution increases, the resulting model parameters approach the OLS parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766db18-998d-421b-a32f-52a234f7ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Data\n",
    "random.seed(123)\n",
    "npts = 200\n",
    "x = np.linspace(0, 100, npts)\n",
    "\n",
    "y = 100+x+random.normal(0, 10, npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea31861-57c1-46a6-8967-ccaf6d88d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit OLS model\n",
    "xx = x.reshape(len(x), 1)\n",
    "w1 = np.ones(len(x)) # adding weights of 1 for illustrative purposes\n",
    "model1 = LinearRegression().fit(xx, y, w1)\n",
    "preds1 = model1.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d2282-553f-465a-9c16-81296890c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up weighting distributions\n",
    "m = np.floor(np.mean(y)) # center weights at central tendency of response data \n",
    "s = np.std(y)\n",
    "rv = norm(loc=m, scale = s/2) \n",
    "rv2 = norm(loc=m, scale = 1) # extreme weight distribution for illustrative purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc241f70-fc4f-4ad0-a812-fb0386043d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Weighted LS\n",
    "w2 = rv.pdf(y)\n",
    "w2 = w2 / np.sum(w2) # normalize weights to sum to 1, not strictly necessary in this example \n",
    "model2 = LinearRegression().fit(xx, y, w2)\n",
    "preds2 = model2.predict(xx)\n",
    "\n",
    "w3 = rv2.pdf(y)\n",
    "w3 = w3 / np.sum(w3) # normalize weights to sum to 1, not strictly necessary in this example \n",
    "model3 = LinearRegression().fit(xx, y, w3)\n",
    "preds3 = model3.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d29b2-2ea7-4d54-b9e3-d34def39e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression lines\n",
    "sns.set(style='whitegrid')\n",
    "p=sns.lineplot(x=x, y=preds1, label=\"OLS\")\n",
    "p=p.set(xlabel=\"X\", ylabel=\"f(X)\")\n",
    "sns.lineplot(x=x, y=preds2, label = \"Weighted (large variance)\")\n",
    "sns.lineplot(x=x, y=preds3, label = \"Weighted (small variance)\")\n",
    "sns.scatterplot(x=x, y=y, alpha=.7)\n",
    "plt.legend()\n",
    "plt.title(\"OLS vs Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277789b-8aa9-42c9-87ab-3d87d4197af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Weighting Distriubtions\n",
    "yy = np.sort(y)\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(6, 6))\n",
    "fig.suptitle('Weight Distributions')\n",
    "ax1.plot(rv.pdf(yy), yy, color=sns.color_palette()[1])\n",
    "ax1.set_title(\"Large Variance\")\n",
    "ax1.set_xticklabels([]);\n",
    "# ax1.set_yticklabels([]);\n",
    "ax2.plot(rv2.pdf(yy), yy, color=sns.color_palette()[2])\n",
    "ax2.set_title(\"Small Variance\")\n",
    "ax2.set_xticklabels([]);\n",
    "# ax2.set_yticklabels([]);\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f306ea-97b1-4319-8f7e-623c336c627a",
   "metadata": {},
   "source": [
    "The weighted least squares model with the small variance gives tiny weight to residuals far away from the sample mean of the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b63a0-9de7-4c15-bde4-4b4466d52b4b",
   "metadata": {},
   "source": [
    "## Fuel Moisture Nonlinear Effect on Rate of Spread\n",
    "\n",
    "[Rate of spread](https://www.nwcg.gov/course/ffm/fire-behavior/83-rate-of-spread#:~:text=The%20rate%20of%20spread%20is,origin%20quickly%20with%20great%20intensity.) (ROS) is a measure of the speed a fire moves (often units of m/s). The following image shows the nonlinear relationship between FM and ROS at a single spatial location, while holding other variables associated with ROS constant. Wildfire spreads most readily in dry fuels, as seen in the peak of the ROS curve at zero FM. The ROS drops off quickly as fuels get wetter, but then it levels off until the ROS is zero, or when the FM reaches the \"extinction value\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14702862-64b5-431f-ac75-a46df30c1b62",
   "metadata": {},
   "source": [
    "![](https://wiki.openwfm.org/mediawiki/images/9/9b/Grass-fmc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d97895-ed01-4060-b01d-b2a7e1fedff4",
   "metadata": {},
   "source": [
    "If the goal of training fuel moisture models is to get more accurate forecasts of wildfire ROS, it is intuitive that models should be trained directly on ROS. Instead of using loss functions on FM, why not construct a loss function directly with ROS? First, wildfire ROS is a complicated multifaceted conce3pt, and it is conceptually much cleaner to directly model fuel moisture and combine it with other observations to get reliable ROS estimates. Mathematically, there are issues related to the following two facts:\n",
    "\n",
    "1. FM is highly correlated in time.\n",
    "2. ROS reaches extinction value relatively quickly for dead fuels.\n",
    "\n",
    "Since fuel moisture content is the \"percent of the dry weight of that specific fuel\" ([from NOAA](https://www.ncei.noaa.gov/access/monitoring/dyk/deadfuelmoisture#:~:text=Fuel%20moisture%20is%20a%20measure,content%20would%20be%20zero%20percent.)), this value can easily go over 100% for very wet fuels, since the water content can weight more than the underlying burnable material. The extinction value for tall grass, depicted above, reaches its extinction moisture value at roughly 25%. Thus, the ROS for tall grass with 25% FM would be the same as that of tall grass with 150% FM. In both cases, the ROS would be zero. \n",
    "\n",
    "This fact, combined with the temporal correlation of FM, makes it potentially undesirable to train FM models directly on ROS. Consider a case when the true FM content was 30% for tall grass. Model 1 predicts 25% FM and Model 2 predicts 150%. Both models would receive a loss of zero for that prediction, since both models predict zero ROS which matches the observed value. However, if atmospheric conditions led to the fuel drying out over time, the models would predict very different ROS within a few hours. Fuels with an FM of 25% would dry out relatively quickly compared to fuels with an FM of 150%, and thus the ROS would be nonzero in the former case much quicker than the latter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94648a-a451-4144-be4c-cce542e526be",
   "metadata": {},
   "source": [
    "### Simulated FM Example\n",
    "\n",
    "Fuel moisture content has a cyclical pattern that corresponds to a 24 hour day, where there are cycles throughout the day of temperature and relative humidity (two of the main theoretical drivers of FM). For this example, we simulate a sinusoidal curve with a decreasing linear trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d397f-463b-42dc-8b4a-a1734fe3de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim data, no rain for simplicity\n",
    "random.seed(456)\n",
    "\n",
    "hours = 400 # Total number of time steps\n",
    "dat = synthetic_data(max_rain = 0, data_noise = .5)  # Sim data from FMDA project code\n",
    "fm = dat['fm'][0:hours]\n",
    "\n",
    "# Manually edit sim data to illustrate point about ROS\n",
    "fm = fm + 20 - .07*np.arange(0, hours) # Shift up by 20, add decreasing trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d6c9f-f66a-4bcb-ac35-38ca382112b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=np.arange(0, hours)\n",
    "plt.plot(h, fm, \"-o\", markersize=3)\n",
    "plt.title(\"Simulated FM\")\n",
    "plt.xlabel(\"Time (hour)\")\n",
    "plt.ylabel(\"FM (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a8b30-035f-487e-9131-6b43295fabfe",
   "metadata": {},
   "source": [
    "We then construct an idealized rate of spread curve from the source above. *Note:* an extinction moisture of about 25 is common for various fuel types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c916197-ddf8-4b65-aeb8-38eefeb621b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Idealized ROS curve\n",
    "x = np.array([0, 5, 10, 15, 20, 25])\n",
    "y = np.array([.05, .025, .02, .018, .01, 0])\n",
    "from scipy.interpolate import CubicSpline\n",
    "xvals = np.linspace(start=0, stop=30, num=100)\n",
    "\n",
    "ros_f = CubicSpline(x, y)\n",
    "def ros(fm):\n",
    "    r = ros_f(fm)\n",
    "    r[fm>25]=0\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(xvals, ros(xvals), \"red\")\n",
    "plt.xlabel(\"Fuel Moisture (%)\")\n",
    "plt.ylabel(\"Rate of Spread (m/s)\")\n",
    "plt.title(\"ROS Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d02f2-f8fc-4c09-80fd-3bc28a7a1d10",
   "metadata": {},
   "source": [
    "Using the previously plotted simulated FM data, we now plot the ROS transformation of this data. Notice that many FM observations near the start of the time period get mapped to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae470c1-236f-4b09-8c33-455d92c5aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROS over time\n",
    "rs = ros(fm)\n",
    "plt.plot(h, rs, \"red\")\n",
    "plt.xlabel(\"Time (hour)\")\n",
    "plt.ylabel(\"ROS (m/s)\")\n",
    "plt.title(\"ROS over Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e23f25-8b5c-468f-a65f-8a55273661c3",
   "metadata": {},
   "source": [
    "### Autoregression Model on Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e3e12-2594-4b4a-a699-2b4c6bdb2c71",
   "metadata": {},
   "source": [
    "We then train a simple Autoregressive model. Autoregression (AR) relates the response variable at time $t$ to response values at previous time steps, or \"lags\". The mathematical form of an AR model with time lags $k=1, 2, ..., K$:\n",
    "\n",
    "$$\n",
    "y_t = \\beta_0 + \\sum_{k=1}^K \\beta_k y_{t-k} +\\epsilon_t\n",
    "$$\n",
    "\n",
    "The terms here are:\n",
    "* $y_t$: Response value at time $t$\n",
    "* $\\beta_0$: Parameter representing the overall mean, or intercept in the linear model context.\n",
    "* $\\beta_k$: Regression coefficient for time lag $k$.\n",
    "* $y_{t-k}$: Observed response value at time $t-k$.\n",
    "* $\\epsilon_t$: Random error component at time $t$. Generally, this is assumed to be normally distributed with mean zero and identically distributed for all times. Given a variance parameter $\\sigma^2$, the noise term is therefore $\\epsilon_t\\sim N(0, \\sigma^2), \\text{ for }t=1,2, ...$\n",
    "\n",
    "Next, we examine autocorrelation plots to get a reasonable value for the number of time lags to examine. Fuel moisture is highly correlated in time, and there is a cyclical effect of the 24 hour weather cycles in a day. The raw autocorrelation plot below (displayed first in order) shows strong correlation across all times. However, the partial autocorrelation plot after that shows the first few lags represent most of that correlation, though the cyclical effect is still evident. Note that there is a small significant peak at roughly 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b8509-56db-4d41-8174-82d6df2fb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46669bf-6da2-41ea-961e-db692566a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_pacf(fm, lags=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8996f-c095-43db-9aec-f02a7e7fb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0923c2-fb1c-414f-aaa9-e09d27857253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 fit with OLS on FM\n",
    "h = h.reshape(-1, 1)\n",
    "h2 = 300\n",
    "fmtr=fm[0:h2]\n",
    "fmte=fm[h2:len(fm)]\n",
    "lags = 48\n",
    "ar1 = AutoReg(fmtr, lags=lags).fit() # training fuel moisture is response\n",
    "fit1 = ar1.predict(start=0, end=h2-1, dynamic=False)\n",
    "fit1 = fit1[lags:h2]  # ignore NAN values at beginning when lags can't be calculated\n",
    "preds1 = ar1.predict(start=len(fmtr), end=len(fmtr)+len(fmte)-1, dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bb914-8aee-4ce3-a223-4d697ffde3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h, fm, \"-o\", markersize=3)\n",
    "plt.plot(h[lags:h2], fit1, label=\"Training\")\n",
    "plt.plot(h[h2:len(h)], preds1, label=\"Forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear Fit on OLS FM Loss\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"FM\")\n",
    "# plt.annotate(\"Training R2=\"+str(np.round(fmmod1.score(Xtr, fmtr), 3)), [325, 30])\n",
    "# plt.annotate(\"Testing R2=\"+str(np.round(fmmod1.score(Xte, fmte), 3)), [325, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78797f91-55c1-483d-b6f4-b9155f8a8b67",
   "metadata": {},
   "source": [
    "Next, transform the fitted and forecasted values from the previous model to rate of spread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d1a72-1d5b-48d8-b4b8-f7e03b4fc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=ros(fm)\n",
    "rstr=rs[0:h2]\n",
    "rste=rs[h2:len(rs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061aa4cc-65ec-4730-8409-5e680f4bad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h, rs)\n",
    "plt.plot(h[lags:h2], ros(fit1), label=\"Training\")\n",
    "plt.plot(h[h2:len(h)], ros(preds1), label=\"Forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear Fit on ROS FM Loss\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"FM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52375f53-e223-4bfe-9626-950c5b8ca19c",
   "metadata": {},
   "source": [
    "A visual examination shows the model does a decent job of forecasting the ROS into the future.\n",
    "\n",
    "Next, we fit an AR model of the same for directly on the transformed response variable. So here, ROS is the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca06afe-c58b-4d58-a09c-98e4cc4b32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 fit OLS on ROS\n",
    "ar2 = AutoReg(rstr, lags=48).fit() # ROS is modeled response\n",
    "fit2 = ar2.predict(start=0, end=h2-1, dynamic=False) # ignore NAN values at beginning when lags can't be calculated\n",
    "fit2 = fit2[lags:h2]  # ignore NAN values at beginning when lags can't be calculated\n",
    "preds2 = ar2.predict(start=len(rstr), end=len(rstr)+len(rste)-1, dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd965b6-c28c-44c1-84f8-9e461742c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h, rs)\n",
    "plt.plot(h[lags:h2], fit2, label=\"Training\")\n",
    "plt.plot(h[h2:len(h)], preds2, label=\"Forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear Fit on ROS Loss\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"ROS\")\n",
    "# plt.annotate(\"R2=\"+str(np.round(fmmod2.score(X, rs), 3)), [0, .025],\n",
    "            # color=(0.8666666666666667, 0.5176470588235295, 0.3215686274509804))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10700b01-0174-4f82-9d61-7bafa8e30c88",
   "metadata": {},
   "source": [
    "Visually, the model performs worse in the forecasting period. Next, we examine the RMSE, with respect to ROS, for the training and forecasting periods for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab72ec-a70c-40e9-a868-57def7ed07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Modeled Response\": [\"FM\", \"ROS\"],\n",
    "    \"Training RMSE\": [\n",
    "        mean_squared_error(ros(fit1), rstr[lags:h2], squared=False), # RMSE with squared = False\n",
    "        mean_squared_error(fit2, rstr[lags:h2], squared=False) \n",
    "    ],\n",
    "    \"Forecast RMSE\": [\n",
    "         mean_squared_error(ros(preds1), rste, squared=False), # RMSE with squared = False\n",
    "        mean_squared_error(preds2, rste, squared=False) \n",
    "    ]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f4e09-5d4e-42fc-8d2b-b0d9316d563b",
   "metadata": {},
   "source": [
    "The AR model trained directly on ROS performs worse than the model trained on FM for both training errors and forecast errors. Also, note that the forecast error is over 4 times the training error for the model trained on ROS, while it is roughly 1.5 times for the FM model. The model trained on ROS is therefore overfitting more than the other model.\n",
    "\n",
    "This is a simple example that shows it is not always desirable to train models directly on the quantity of interest. In this case, it is better to train directly on FM, then transform the predictions to ROS. \n",
    "\n",
    "The ROS transformation of FM effectively \"throws out\" information by collapsing a whole range of the outcome variable to zero (the extinction moisture). I hypothesize that it is better to train on FM than ROS for this reason. It is possible that simple AR models are ill equiped at modeling the ROS curve. So more models need to be investigated before we can confidently say that it is preferrable to train on FM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1021b8-c541-4a68-a0d8-992399cc6fc0",
   "metadata": {},
   "source": [
    "## Proposed Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82693d-6c5e-4219-a4c3-c081d117fa23",
   "metadata": {},
   "source": [
    "In order to get the most accurate ROS forecasts, we have so far presented two approaches that can be thought of as opposite extremes. One approach is to train models with FM as the response and minimize the typical Residual Sum of Squares (RSS). After the initial training, we then transform the forecasts from FM to ROS. The drawback of this approach is that the training procedure will minimize errors across the entire observed range of FM values, and we might miss out on models that perform better for very dry fuels. The other approach is to transform FM observations to ROS first, and then train models to minimize the RSS of the ROS values. The drawback of this approach is that the ROS transformation collapses many FM observations to zero, at the extinction moisture level, so we lose information that is potentially useful for time dependent forecasts. I will refer to these two loss function approaches as the \"baseline\" loss functions. The goal of this project is to construct loss functions that get the best of both of baseline loss functions. In other words, we want to train FM models to be most accurate for very dry fuels without ignoring the information that saturated fuels give us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd10df-11eb-4ccf-8f43-520a1d2ed43a",
   "metadata": {},
   "source": [
    "### Weighted Average of Baseline Loss Functions\n",
    "\n",
    "Let the size of the training sample be $n$. For each observed response value $y_1, y_2, ..., y_n$, the baseline methods assign a weight to each model residual. Then the model is trained to minimize the following weighted residual sum of squares. If the loss function is the RSS on FM values, the weights are uniform and the minimization procedure is equivalent to the unweighted case. Note that the weights will sum to 1 in this case.\n",
    "\n",
    "$$w_i = \\frac{1}{n} \\text{ for all }i = 1, 2, ..., n$$\n",
    "$$\\sum_{i=1}^n w_i = 1$$\n",
    "\n",
    "\n",
    "The other baseline case, where the FM observations are transformed to ROS, is equivalent to a weighted least squares procedure with the weights coming from the density given by the FM versus ROS curve. The weights are then normalized to sum to one. As a simple example, suppose we have observed FM values of $0, 25,$ and $30$. We visualize those points on the ROS curve below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1187aa6-1407-4be2-9ae5-83789d7c017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0, 25, 30])\n",
    "plt.plot(xvals, ros(xvals), \"red\")\n",
    "plt.plot(y, ros(y), 'bo', label = \"Observed FM values\")\n",
    "plt.xlabel(\"Fuel Moisture (%)\")\n",
    "plt.ylabel(\"Rate of Spread (m/s)\")\n",
    "plt.title(\"ROS Curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4857fed-9803-4382-89f5-23ea39ff209b",
   "metadata": {},
   "source": [
    "This would lead to unnormalized weights of $0.05, 0, $ and $0$.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a72ac-882f-49cd-8188-b5e7d2d8da03",
   "metadata": {},
   "source": [
    "### Gamma Function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c6e953-496f-46f9-b044-261ee8ced2e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Proposed Experiment\n",
    "\n",
    "My research hypothesis is that a weighted loss function for training fuel moisture models, which places more weight on lower values of FM, will result in more accurate ROS forecast than either an unweighted loss function on FM or a loss function directly on ROS. The weighting scheme is intended to assign a larger loss to model errors for low values of fuel moisture, since small errors in FM in that range lead to large differences in ROS. The fully realized version of this project would compare ROS forecasts to real observed fires with various fuel types. For a Masters' Project, I will consider the theoretical ROS at single spatial locations with only 10-hour dead fuel moisture (fm10). The fuel moisture models will be evaluated by their ROS forecast accuracy. Additionally, I need to specify spatial and temporal domains for analysis. To test my hypothesis in the simplified framework, I propose the following experimental design. \n",
    "\n",
    "1. Build a Testing Dataset:\n",
    "\n",
    "**Spatial Frame**: Collect hourly fm10 observations for all RAWS stations in Colorado with complete data to run fuel moisture models (46 in total). \n",
    "\n",
    "**Time Frame**: Collect fm10 observations from May through September, corresponding to the Colorado Wildfire Season as defined by the [Western Fire Chiefs Association](https://wfca.com/articles/colorado-fire-season/). These time periods will be divided into 5 periods of training and testing, one for each month. The **training period** will be days 1-20 of each month, and the **testing period** will be days 21-30 or 31 of each month.\n",
    "\n",
    "This will result in a dataset for 225 potential model runs (46 stations times 5 time periods).\n",
    "\n",
    "2. Define a set of Fuel Moisture Models:\n",
    "\n",
    "I will consider a few different models to examine how changing the loss function changes the ROS forecast accuracy:\n",
    "\n",
    "* Simple Linear Regression Model: Including all FM variables as predictors. I include this because it will be simple to construct and deploy and analyze how it interacts with different loss functions.\n",
    "* Auto-regressive Linear Model: The only predictor will be the 1 hour time lag of FM. I developed such a model for Data 2 Policy, which showed relatively strong accuracy. I include it to investigate how the loss functions interact with a time-series based model.\n",
    "* Physics-Initiated Recurrent Neural Network: This model was developed by Jan Mandel and it is part of my ongoing research to assist him with developing this model.\n",
    "\n",
    "3. Build a set of Candidate Loss Functions:\n",
    "\n",
    "* Unweighted RSS on FM. This would be one loss function.\n",
    "* Unweigthted RSS on ROS. This would also be one loss function.\n",
    "* Weighted RSS on FM. This would be a set of loss functions. I will consider Gamma distributions with various parameter pairs. I select Gamma distributions a priori: they have positive support (FM cannot be negative) and they are flexible to get different shapes of the resulting distributions.\n",
    "\n",
    "My hypothesis is that some loss function from the third set of loss functions will lead to the best forecasts of ROS.           \n",
    "\n",
    "4. Fit the models and forecast ROS:\n",
    "\n",
    "For each model and each loss function, train the model on 20 days of data, for the spatial locations I describe above, and forecast ROS 10 days into the future.\n",
    "\n",
    "5. Evaluate Forecast Accuracy:\n",
    "\n",
    "For each model run, calculate the accuracy of the ROS forecast by calculating the root mean squared error (RMSE) of the resulting ROS predictions. I will then summarize the average RMSE at each location and time period. Following that, I will analyze whether there were systematic differences between the different FM models, e.g. whether one loss function work better for the RNN than for the linear regression.\n",
    "\n",
    "\n",
    "**Jan NOTES 10-1**\n",
    "Train on 10 hour, but define ROS for 1 of 13 fuel categories. Discuss how to go to 1hr and 100hr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680cd64f-8c7e-4bcc-afff-6b3db00dbf78",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Open Wildland Fire Modeling E Community. https://wiki.openwfm.org/wiki/\n",
    "* National Wildfire Coordinating Group (NWCG). https://www.nwcg.gov/course/ffm/\n",
    "* *Dead Fuel Moisture*, NOAA National Centers for Environmental Information. https://www.ncei.noaa.gov/access/monitoring/dyk/deadfuelmoisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2d262-9e5a-4e1a-bfda-506cef02e6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
