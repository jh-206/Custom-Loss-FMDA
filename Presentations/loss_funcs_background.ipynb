{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fe853-c3ab-481b-9470-b9b7f5f9c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../src')\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f9289-2126-4032-ba80-dcceda99b231",
   "metadata": {},
   "source": [
    "# Custom Loss Functions for Fuel Moisture Models\n",
    "\n",
    "*Author:* Jonathon Hirschi\n",
    "\n",
    "A loss function is intended to measure the fitting accuracy of a statistical model. Loss functions are used for training the parameters machine learning models.\n",
    "\n",
    "The purpose of this notebook is to discuss training fuel moisture models with various loss functions to try to account for the nonlinear effect of fuel moisture on wildfire rate of spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95fa10-9887-4668-a6ee-fd867acb99d0",
   "metadata": {},
   "source": [
    "## Example with Weighted Least Squares\n",
    "\n",
    "To illustrate the effect of changing loss functions, consider a simple linear model with one predictor for $n$ samples:\n",
    "\n",
    "$$f(x_i, \\pmb\\beta) = \\beta_0 + \\beta_1 x_i, \\text{ for }i=1,..., n$$\n",
    "\n",
    "Ordinary least squares (OLS) is the most basic method of estimating the $\\beta$ parameter values. The method minimizes the residual sum of squares (RSS), the loss function in this case. Equal weight is given to each residual value in the loss function,\n",
    "\n",
    "$$r_i = y_i - f(x_i, \\pmb \\beta)$$\n",
    "\n",
    "$$\\pmb{\\hat\\beta_{OLS}} = argmin_\\beta \\sum_{i=1}^n r_i^2$$\n",
    "\n",
    "Weighted least squares minimizes the weighted residual sum of squares, with a weight $w_i$ applied to each residual value. In principle, the weights could come from anywhere. \n",
    "\n",
    "$$\\pmb{\\hat\\beta_{W}} = argmin_\\beta \\sum_{i=1}^n w_ir_i^2$$\n",
    "\n",
    "In the following example, the OLS model for simulated data is compared to two different weighting schemes. In both cases, the weights come from normal distributions centered at the observed mean of the response value, but one has a large variance and the other has a much smaller variance. In this formulation of weights, as the variance of the normal distribution increases, the resulting model parameters approach the OLS parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766db18-998d-421b-a32f-52a234f7ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Data\n",
    "random.seed(123)\n",
    "npts = 200\n",
    "x = np.linspace(0, 100, npts)\n",
    "\n",
    "y = 100+x+random.normal(0, 10, npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea31861-57c1-46a6-8967-ccaf6d88d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit OLS model\n",
    "xx = x.reshape(len(x), 1)\n",
    "w1 = np.ones(len(x)) # adding weights of 1 for illustrative purposes\n",
    "model1 = LinearRegression().fit(xx, y, w1)\n",
    "preds1 = model1.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d2282-553f-465a-9c16-81296890c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up weighting distributions\n",
    "m = np.floor(np.mean(y)) # center weights at central tendency of response data \n",
    "s = np.std(y)\n",
    "rv = norm(loc=m, scale = s/2) \n",
    "rv2 = norm(loc=m, scale = 1) # extreme weight distribution for illustrative purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc241f70-fc4f-4ad0-a812-fb0386043d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Weighted LS\n",
    "w2 = rv.pdf(y)\n",
    "w2 = w2 / np.sum(w2) # normalize weights to sum to 1, not strictly necessary in this example \n",
    "model2 = LinearRegression().fit(xx, y, w2)\n",
    "preds2 = model2.predict(xx)\n",
    "\n",
    "w3 = rv2.pdf(y)\n",
    "w3 = w3 / np.sum(w3) # normalize weights to sum to 1, not strictly necessary in this example \n",
    "model3 = LinearRegression().fit(xx, y, w3)\n",
    "preds3 = model3.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d29b2-2ea7-4d54-b9e3-d34def39e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression lines\n",
    "sns.set(style='whitegrid')\n",
    "p=sns.lineplot(x=x, y=preds1, label=\"OLS\")\n",
    "p=p.set(xlabel=\"X\", ylabel=\"f(X)\")\n",
    "sns.lineplot(x=x, y=preds2, label = \"Weighted (large variance)\")\n",
    "sns.lineplot(x=x, y=preds3, label = \"Weighted (small variance)\")\n",
    "sns.scatterplot(x=x, y=y, alpha=.7)\n",
    "plt.legend()\n",
    "plt.title(\"OLS vs Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277789b-8aa9-42c9-87ab-3d87d4197af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Weighting Distriubtions\n",
    "yy = np.sort(y)\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(6, 6))\n",
    "fig.suptitle('Weight Distributions')\n",
    "ax1.plot(rv.pdf(yy), yy, color=sns.color_palette()[1])\n",
    "ax1.set_title(\"Large Variance\")\n",
    "ax1.set_xticklabels([]);\n",
    "# ax1.set_yticklabels([]);\n",
    "ax2.plot(rv2.pdf(yy), yy, color=sns.color_palette()[2])\n",
    "ax2.set_title(\"Small Variance\")\n",
    "ax2.set_xticklabels([]);\n",
    "# ax2.set_yticklabels([]);\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f306ea-97b1-4319-8f7e-623c336c627a",
   "metadata": {},
   "source": [
    "The weighted least squares model with the small variance gives tiny weight to residuals far away from the sample mean of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2d262-9e5a-4e1a-bfda-506cef02e6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
