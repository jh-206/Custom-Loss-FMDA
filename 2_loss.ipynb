{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f01fe9-1006-4182-b26f-cd33eaeef062",
   "metadata": {},
   "source": [
    "# Test Loss Functions on Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d5c58-a711-4371-91b3-6de72c7b9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "# Local modules\n",
    "from data_funcs import train_test_split_spacetime\n",
    "from fmda_models import LM, XGB, RF\n",
    "from metrics import ros, rmse\n",
    "import reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb86ca1-547c-4eb8-a241-a3ad3f96fec3",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042d139-16f4-45a7-bdbf-25e7926b0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/raws_df.pkl\")\n",
    "df = df.dropna()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef1588-8223-4462-ad1e-bfa7991a2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d924a1-f9c9-45a0-bdb1-6fb145da83f6",
   "metadata": {},
   "source": [
    "## Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c207536-5c28-4c47-9c3d-592d7d323f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/params.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a0074-804a-4953-9925-e235ca34ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    models = {\n",
    "        'xgb' : XGB(params['xgb']),\n",
    "        'lm' : LM(params['lm']),\n",
    "        'rf' : RF(params['rf'])\n",
    "    }\n",
    "\n",
    "    return models\n",
    "\n",
    "models = initialize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fecb1-b761-45ff-88cf-e34ef36bcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp_function(w):\n",
    "    def exp_function(y_train):\n",
    "        return tf.exp(tf.multiply(-w, y_train))\n",
    "    return exp_function\n",
    "\n",
    "## Function test:\n",
    "# fun = create_exp_function(.05)\n",
    "# fun(y_train = np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1560f2-ca18-45b0-bc59-2ba433f224e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_setup(ws = None):\n",
    "    loss_fucs = [\"rss\", \"exp\", \"ros\"]\n",
    "    # set up return dictionary\n",
    "    loss = {\n",
    "        'rss' : {\n",
    "            'w_func' : None\n",
    "        }\n",
    "    } \n",
    "    # Using input omega parameter list, add dictionary key for exponential weighting for each omega in list \n",
    "    if ws is not None:\n",
    "        for w in ws:\n",
    "            assert isinstance(w, float) # Check that given list of floats\n",
    "            dname = f\"exp_{w}\" # create name of dictionary key\n",
    "            loss[dname] = {\n",
    "                'w_func' : create_exp_function(w)\n",
    "            }\n",
    "    loss[\"ros\"] = {'w_func': ros}\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b0e03-bffd-4c5b-8971-ee974b720e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_grid=np.round(np.linspace(0.01, .25, 10), 4)\n",
    "print(f\"Grid of Omega Weights: {weight_grid}\")\n",
    "loss_dict = loss_setup(ws=weight_grid)\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaab300-75b6-4c7b-83d8-6964082edaf5",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053e392-7e9a-4d45-9e66-7cae5649fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COLUMNS SUBSET\n",
    "cols = [\"Ed\", \"Ew\", \"rain\", \"wind\", \"solar\", \"hour\", \"doy\", \"lat\", \"lon\"]\n",
    "\n",
    "# Get unique month and year combos in the data\n",
    "month_year = df.index.to_period('M').unique()\n",
    "print(month_year)\n",
    "\n",
    "reproducibility.set_seed(42)\n",
    "\n",
    "# for my in month_year:\n",
    "#     print(\"~\"*50)\n",
    "#     month = my.month\n",
    "#     year = my.year\n",
    "#     print(f\"Splitting data for month: {my}\")\n",
    "#     df_temp = df[(df.index.month == month) & (df.index.year == year)]\n",
    "#     print(f\"Total observations: {df_temp.shape}\")\n",
    "#     X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "#         df_temp, \n",
    "#         test_days = 2,\n",
    "#         spatial_test_frac = 0.2,\n",
    "#         verbose = True\n",
    "#     )\n",
    "#     X_train = X_train[cols]\n",
    "#     X_test = X_test[cols]\n",
    "\n",
    "my = month_year[1]\n",
    "month = my.month\n",
    "year = my.year\n",
    "print(f\"Splitting data for month: {my}\")\n",
    "df_temp = df[(df.index.month == month) & (df.index.year == year)]\n",
    "print(f\"Total observations: {df_temp.shape}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "    df_temp, \n",
    "    test_days = 2,\n",
    "    spatial_test_frac = 0.2,\n",
    "    verbose = True\n",
    ")\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8f2d1-0879-4a96-b192-d19f696fa249",
   "metadata": {},
   "source": [
    "For each loss function and each model, we will collect 2 arrays of errors on the test set. One for the RMSE on the test fuel moisture observations, and another one on the RMSE for the same observations transformed to ROS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee410d-34b9-46b7-acb6-171bca0d0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loss_dict:\n",
    "    loss_dict[l][f\"errs\"]={}\n",
    "    for mod in models:\n",
    "        loss_dict[l][f\"errs\"][mod] = {\n",
    "            \"rmse_test\" : [],\n",
    "            \"rmse_test_ROS\" : []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5791c-79ae-4f1d-8b40-7e6fae9ea2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique month and year combos in the data\n",
    "month_year = df.index.to_period('M').unique()\n",
    "print(month_year)\n",
    "reproducibility.set_seed(42)\n",
    "for my in month_year:\n",
    "    print(\"~\"*80)\n",
    "    month = my.month\n",
    "    year = my.year\n",
    "    print(f\"Splitting data for month: {my}\")\n",
    "    df_temp = df[(df.index.month == month) & (df.index.year == year)]\n",
    "    print(f\"Total observations: {df_temp.shape}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split_spacetime(\n",
    "        df_temp, \n",
    "        test_days = 2,\n",
    "        spatial_test_frac = 0.2,\n",
    "        verbose = True\n",
    "    )\n",
    "    X_train = X_train[cols]\n",
    "    X_test = X_test[cols]\n",
    "    for l in loss_dict:\n",
    "        print(\"~\"*50)\n",
    "        print(f\"Running models for loss func: {l}\")\n",
    "        if loss_dict[l]['w_func'] is not None:\n",
    "            weights = loss_dict[l]['w_func'](y_train)\n",
    "        else:\n",
    "            weights = None\n",
    "        # Reinitialize models dictionary to prevent multiple fitting iterations\n",
    "        # if True:\n",
    "        #     models = initialize_models()\n",
    "        for mod in models:\n",
    "            print(f\"Fitting {mod}\")\n",
    "            models[mod].fit(X_train, y_train, weights)\n",
    "            preds = models[mod].predict(X_test)\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test\"].append(rmse(preds, y_test))\n",
    "            loss_dict[l][f\"errs\"][mod][\"rmse_test_ROS\"].append(rmse(ros(preds), ros(y_test)))\n",
    "            print(f\"Test RMSE for {mod}: {rmse(preds, y_test)}\")\n",
    "            print(f\"Test ROS RMSE for {mod}: {rmse(ros(preds), ros(y_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c491b-454f-4a60-9a47-88ee116a8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vec = [*loss_dict.keys()]\n",
    "models_vec = [*models.keys()]\n",
    "df1 = pd.DataFrame(np.zeros((len(loss_vec), len(models_vec))), index=loss_vec, columns=models_vec)\n",
    "df2 = pd.DataFrame(np.zeros((len(loss_vec), len(models_vec))), index=loss_vec, columns=models_vec)\n",
    "\n",
    "for l in loss_dict:\n",
    "    for mod in loss_dict[l][\"errs\"]:\n",
    "        df1.loc[l, mod] = np.mean(loss_dict[l][\"errs\"][mod]['rmse_test'])\n",
    "        df2.loc[l, mod] = np.mean(loss_dict[l][\"errs\"][mod]['rmse_test_ROS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86132f-57b4-49e3-a3f7-d5de85311d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83836e-ddee-43ed-9f11-8c4ff5a92725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4ec8d-b34b-4cd6-803f-899b69718d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1.index, df1[\"lm\"])\n",
    "plt.xlabel('Loss Function')\n",
    "plt.ylabel('RMSE Test Data')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Test RMSE by Loss Function - Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e384c-a4f4-4920-b03f-c239eeead237",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(models_vec) # number of rows of subplots\n",
    "fig, axes = plt.subplots(N, 2, figsize=(10, 5*N))\n",
    "for i in range(0, len(models_vec)):\n",
    "    mod = models_vec[i]\n",
    "    # Access the subplot at row i, column 0\n",
    "    ax1 = axes[i, 0]\n",
    "    ax1.scatter(df1.index, df1[mod])\n",
    "    ax1.tick_params(axis='x', rotation=90)\n",
    "    ax1.set_title(f'Test RMSE - Model {mod}')\n",
    "\n",
    "    # Access the subplot at row i, column 1\n",
    "    ax2 = axes[i, 1]\n",
    "    ax2.scatter(df2.index, df2[mod])\n",
    "    ax2.tick_params(axis='x', rotation=90)\n",
    "    ax2.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    ax2.set_title(f'Test RMSE on ROS - Model {mod}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337e1e1-f8ac-415c-9cb4-578b0d9b880d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc0226-4903-45e8-8ef3-06f28602b62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
